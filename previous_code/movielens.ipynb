{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2808007",
   "metadata": {
    "id": "QdDq00DpRoJq",
    "papermill": {
     "duration": 0.012184,
     "end_time": "2024-04-01T11:58:02.057946",
     "exception": false,
     "start_time": "2024-04-01T11:58:02.045762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Recommendation Systems\n",
    "# Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb5a3e",
   "metadata": {
    "id": "g7SGcGmeR1Xk",
    "papermill": {
     "duration": 0.011218,
     "end_time": "2024-04-01T11:58:02.081005",
     "exception": false,
     "start_time": "2024-04-01T11:58:02.069787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Configurations from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55191a9a",
   "metadata": {
    "id": "djvqvxTfR5c8",
    "papermill": {
     "duration": 0.011388,
     "end_time": "2024-04-01T11:58:02.103892",
     "exception": false,
     "start_time": "2024-04-01T11:58:02.092504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For loading dataset, we use the dataset from the GitHub [repo](https://github.com/hexiangnan/neural_collaborative_filtering) of the original paper. The datasets in the research are:\n",
    "1. Movielens-1M\n",
    "2. Pinterest\n",
    "\n",
    "Detailed information is availaible in the paper itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d6ca10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:02.127731Z",
     "iopub.status.busy": "2024-04-01T11:58:02.127363Z",
     "iopub.status.idle": "2024-04-01T11:58:06.919410Z",
     "shell.execute_reply": "2024-04-01T11:58:06.918419Z"
    },
    "id": "TfAk7NN73r3C",
    "outputId": "5470da71-6a5c-4313-f6f7-e6ccd38dd574",
    "papermill": {
     "duration": 4.806096,
     "end_time": "2024-04-01T11:58:06.921660",
     "exception": false,
     "start_time": "2024-04-01T11:58:02.115564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'neural_collaborative_filtering'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hexiangnan/neural_collaborative_filtering.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f626c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:06.945106Z",
     "iopub.status.busy": "2024-04-01T11:58:06.944558Z",
     "iopub.status.idle": "2024-04-01T11:58:07.968401Z",
     "shell.execute_reply": "2024-04-01T11:58:07.967301Z"
    },
    "id": "7unsDz1uTO30",
    "papermill": {
     "duration": 1.038163,
     "end_time": "2024-04-01T11:58:07.970944",
     "exception": false,
     "start_time": "2024-04-01T11:58:06.932781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\Documents\\DA-IICT\\Arpit_rana\\MajorProject\\previous_code\n",
      "['movielens.ipynb', 'ncf_tensorflow-main.zip', 'neural_collaborative_filtering']\n"
     ]
    }
   ],
   "source": [
    "# !cp '/kaggle/working/neural_collaborative_filtering/Data' '/kaggle/working/' -r\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee361ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\Documents\\DA-IICT\\Arpit_rana\\MajorProject\\previous_code\\neural_collaborative_filtering\n",
      "['.git', 'Data', 'Dataset.py', 'Dockerfile', 'evaluate.py', 'GMF.py', 'LICENSE', 'MLP.py', 'NeuMF.py', 'Pretrain', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "os.chdir('neural_collaborative_filtering')\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f2317",
   "metadata": {
    "id": "uZZBlo8zU21R",
    "papermill": {
     "duration": 0.010431,
     "end_time": "2024-04-01T11:58:07.993734",
     "exception": false,
     "start_time": "2024-04-01T11:58:07.983303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22f05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR) \n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd063365",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ebde35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:08.016771Z",
     "iopub.status.busy": "2024-04-01T11:58:08.016434Z",
     "iopub.status.idle": "2024-04-01T11:58:20.531613Z",
     "shell.execute_reply": "2024-04-01T11:58:20.530578Z"
    },
    "id": "i90m6p-eU4aS",
    "papermill": {
     "duration": 12.529594,
     "end_time": "2024-04-01T11:58:20.534046",
     "exception": false,
     "start_time": "2024-04-01T11:58:08.004452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, concatenate, multiply\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722a39c",
   "metadata": {
    "id": "N9H4tLezzhOJ",
    "papermill": {
     "duration": 0.010494,
     "end_time": "2024-04-01T11:58:20.555731",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.545237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac644730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:20.578948Z",
     "iopub.status.busy": "2024-04-01T11:58:20.578094Z",
     "iopub.status.idle": "2024-04-01T11:58:20.594199Z",
     "shell.execute_reply": "2024-04-01T11:58:20.593482Z"
    },
    "id": "MKtb0G02WTBh",
    "papermill": {
     "duration": 0.029654,
     "end_time": "2024-04-01T11:58:20.596089",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.566435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    '''\n",
    "    Dataset Class for making dataset input for the models\n",
    "    trainMatrix: training Matrix of the data\n",
    "    testRatings: positive test interactions\n",
    "    testNegatives: negative test interactions sampled for each user\n",
    "    '''\n",
    "\n",
    "    def __init__(self, path):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.trainMatrix = self.load_rating_file_as_matrix(path + \".train.rating\")\n",
    "        self.testRatings = self.load_rating_file_as_list(path + \".test.rating\")\n",
    "        self.testNegatives = self.load_negative_file(path + \".test.negative\")\n",
    "        assert len(self.testRatings) == len(self.testNegatives)\n",
    "\n",
    "        self.num_users, self.num_items = self.trainMatrix.shape\n",
    "\n",
    "    def load_rating_file_as_list(self, filename):\n",
    "        ratingList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item = int(arr[0]), int(arr[1])\n",
    "                ratingList.append([user, item])\n",
    "                line = f.readline()\n",
    "        return ratingList\n",
    "\n",
    "    def load_negative_file(self, filename):\n",
    "        negativeList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                negatives = []\n",
    "                for x in arr[1: ]:\n",
    "                    negatives.append(int(x))\n",
    "                negativeList.append(negatives)\n",
    "                line = f.readline()\n",
    "        return negativeList\n",
    "\n",
    "    def load_rating_file_as_matrix(self, filename):\n",
    "        '''\n",
    "        Read .rating file and Return dok matrix.\n",
    "        The first line of .rating file is: num_users\\t num_items\n",
    "        '''\n",
    "        # Get number of users and items\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                u, i = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, u)\n",
    "                num_items = max(num_items, i)\n",
    "                line = f.readline()\n",
    "        # Construct matrix\n",
    "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                if (rating > 0):\n",
    "                    mat[user, item] = 1.0\n",
    "                line = f.readline()\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea40dc4",
   "metadata": {
    "id": "csXwN9cl2U1-",
    "papermill": {
     "duration": 0.011335,
     "end_time": "2024-04-01T11:58:20.618642",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.607307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a75d8828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:20.642527Z",
     "iopub.status.busy": "2024-04-01T11:58:20.642228Z",
     "iopub.status.idle": "2024-04-01T11:58:20.656671Z",
     "shell.execute_reply": "2024-04-01T11:58:20.655806Z"
    },
    "id": "quclaI95X9a_",
    "papermill": {
     "duration": 0.028721,
     "end_time": "2024-04-01T11:58:20.658678",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.629957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from time import time\n",
    "#from numba import jit, autojit\n",
    "\n",
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_testNegatives = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _testNegatives\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _testNegatives = testNegatives\n",
    "    _K = K\n",
    "\n",
    "    hits, ndcgs = [],[]\n",
    "    if(num_thread > 1): # Multi-thread\n",
    "        pool = multiprocessing.Pool(processes=num_thread)\n",
    "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        hits = [r[0] for r in res]\n",
    "        ndcgs = [r[1] for r in res]\n",
    "        return (hits, ndcgs)\n",
    "    # Single thread\n",
    "    for idx in range(len(_testRatings)):\n",
    "        (hr,ndcg) = eval_one_rating(idx)\n",
    "        hits.append(hr)\n",
    "        ndcgs.append(ndcg)\n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    items = _testNegatives[idx]\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    predictions = _model.predict([users, np.array(items)],\n",
    "                                 batch_size=100, verbose=0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "\n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "332ede1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58304059",
   "metadata": {
    "id": "BN5AgtadzTlI",
    "papermill": {
     "duration": 0.010553,
     "end_time": "2024-04-01T11:58:20.680084",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.669531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eddc6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\Documents\\DA-IICT\\Arpit_rana\\MajorProject\\previous_code\\neural_collaborative_filtering\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "508fed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " 'Data',\n",
       " 'Dataset.py',\n",
       " 'Dockerfile',\n",
       " 'evaluate.py',\n",
       " 'GMF.py',\n",
       " 'LICENSE',\n",
       " 'MLP.py',\n",
       " 'NeuMF.py',\n",
       " 'Pretrain',\n",
       " 'README.md']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fba7d4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/dhruv/Documents/DA-IICT/Arpit_rana/MajorProject/previous_code/neural_collaborative_filtering/Data')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "\n",
    "Path(os.getcwd(), \"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f462621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:20.702878Z",
     "iopub.status.busy": "2024-04-01T11:58:20.702577Z",
     "iopub.status.idle": "2024-04-01T11:58:20.709449Z",
     "shell.execute_reply": "2024-04-01T11:58:20.708164Z"
    },
    "id": "87kukF6iVar6",
    "outputId": "24ed2030-f1f7-4eba-b36a-e912dbd9ba1b",
    "papermill": {
     "duration": 0.020311,
     "end_time": "2024-04-01T11:58:20.711399",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.691088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "path : c:\\Users\\dhruv\\Documents\\DA-IICT\\Arpit_rana\\MajorProject\\previous_code\\neural_collaborative_filtering\\Data\n",
      "dataset : ml-1m\n",
      "regs : [0, 0]\n",
      "lr : 0.001\n",
      "batch_size : 256\n",
      "epochs : 10\n",
      "learner : adam\n",
      "num_factors : 10\n",
      "num_layers : 3\n",
      "num_neg : 2\n",
      "verbose : 2\n",
      "out : True\n"
     ]
    }
   ],
   "source": [
    "configurations = {\n",
    "    'path': Path(os.getcwd()) / \"Data\",\n",
    "    'dataset': 'ml-1m',\n",
    "    'regs': [0, 0],\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'epochs': 10,          ## Training Epochs\n",
    "    'learner': 'adam',\n",
    "    'num_factors': 10,\n",
    "    'num_layers': 3,\n",
    "    'num_neg': 2,\n",
    "    'verbose': 2,\n",
    "    'out': True,\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7f54ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done [14.4 s]. #user=6040, #item=3706, #train=994169, #test=6040\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "t1 = time()\n",
    "\n",
    "dataset_path = os.path.join(configurations['path'], configurations['dataset'])\n",
    "# print(dataset_path)\n",
    "\n",
    "dataset = Dataset(dataset_path)\n",
    "\n",
    "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
    "num_users, num_items = train.shape\n",
    "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
    "      %(time()-t1, num_users, num_items, train.nnz, len(testRatings)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e1d7770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:20.734134Z",
     "iopub.status.busy": "2024-04-01T11:58:20.733672Z",
     "iopub.status.idle": "2024-04-01T11:58:20.742105Z",
     "shell.execute_reply": "2024-04-01T11:58:20.741205Z"
    },
    "id": "hEh518B3We9e",
    "papermill": {
     "duration": 0.02169,
     "end_time": "2024-04-01T11:58:20.743954",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.722264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(regs[0]))(user_input)\n",
    "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=latent_dim, name='item_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(regs[1]))(item_input)\n",
    "\n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User)\n",
    "    item_latent = Flatten()(MF_Embedding_Item)\n",
    "\n",
    "    # Element-wise product of user and item embeddings\n",
    "    predict_vector = multiply([user_latent, item_latent])\n",
    "\n",
    "    # Final prediction layer\n",
    "    #prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)\n",
    "    prediction = Dense(1, activation='sigmoid', name = 'prediction')(predict_vector)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input],\n",
    "                outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffc2db1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:20.766530Z",
     "iopub.status.busy": "2024-04-01T11:58:20.766232Z",
     "iopub.status.idle": "2024-04-01T11:58:20.772724Z",
     "shell.execute_reply": "2024-04-01T11:58:20.771843Z"
    },
    "id": "zueSUt4UWlx7",
    "papermill": {
     "duration": 0.019849,
     "end_time": "2024-04-01T11:58:20.774563",
     "exception": false,
     "start_time": "2024-04-01T11:58:20.754714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    num_users = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u, j) in train:\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cf3f71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:40.908332Z",
     "iopub.status.busy": "2024-04-01T11:58:40.907993Z",
     "iopub.status.idle": "2024-04-01T11:58:41.666980Z",
     "shell.execute_reply": "2024-04-01T11:58:41.666029Z"
    },
    "id": "jXaKqMxZXUuu",
    "outputId": "07c85c16-7ad7-401c-938b-605c199cbbd4",
    "papermill": {
     "duration": 0.773298,
     "end_time": "2024-04-01T11:58:41.669248",
     "exception": false,
     "start_time": "2024-04-01T11:58:40.895950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,060</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m60,400\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m37,060\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m11\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,471</span> (380.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,471\u001b[0m (380.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,471</span> (380.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,471\u001b[0m (380.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = get_GMF_model(num_users, num_items, configurations['num_factors'], configurations['regs'])\n",
    "if configurations['learner'].lower() == \"adagrad\":\n",
    "    model.compile(optimizer=Adagrad(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=RMSprop(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"adam\":\n",
    "    model.compile(optimizer=Adam(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "else:\n",
    "    model.compile(optimizer=SGD(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cafa6cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:42.699122Z",
     "iopub.status.busy": "2024-04-01T11:58:42.698787Z",
     "iopub.status.idle": "2024-04-01T11:58:42.703448Z",
     "shell.execute_reply": "2024-04-01T11:58:42.702463Z"
    },
    "id": "9MUg9pcbax5P",
    "papermill": {
     "duration": 0.020282,
     "end_time": "2024-04-01T11:58:42.705520",
     "exception": false,
     "start_time": "2024-04-01T11:58:42.685238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b60648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T11:58:42.730725Z",
     "iopub.status.busy": "2024-04-01T11:58:42.730451Z",
     "iopub.status.idle": "2024-04-01T12:04:26.792701Z",
     "shell.execute_reply": "2024-04-01T12:04:26.791673Z"
    },
    "id": "icRFrg-cXzJo",
    "outputId": "04dedc39-d376-444a-e5ea-ae14cc8aab3d",
    "papermill": {
     "duration": 344.089518,
     "end_time": "2024-04-01T12:04:26.807172",
     "exception": false,
     "start_time": "2024-04-01T11:58:42.717654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.1015, NDCG = 0.0465\t [457.4 s]\n"
     ]
    }
   ],
   "source": [
    "# Init performance\n",
    "t1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "#mf_embedding_norm = np.linalg.norm(model.get_layer('user_embedding').get_weights())+np.linalg.norm(model.get_layer('item_embedding').get_weights())\n",
    "#p_norm = np.linalg.norm(model.get_layer('prediction').get_weights()[0])\n",
    "print('Init: HR = %.4f, NDCG = %.4f\\t [%.1f s]' % (hr, ndcg, time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d3fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:04:26.869018Z",
     "iopub.status.busy": "2024-04-01T12:04:26.868368Z",
     "iopub.status.idle": "2024-04-01T12:37:27.973301Z",
     "shell.execute_reply": "2024-04-01T12:37:27.972327Z"
    },
    "id": "g4hljeM9YCSw",
    "outputId": "b9460a45-cac0-401a-e9ab-93fbe442a5e7",
    "papermill": {
     "duration": 1981.133931,
     "end_time": "2024-04-01T12:37:27.988917",
     "exception": false,
     "start_time": "2024-04-01T12:04:26.854986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "\n",
    "for epoch in range(configurations['epochs']):\n",
    "    t1 = time()\n",
    "    # Generate training instances\n",
    "    user_input, item_input, labels = get_train_instances(train, configurations['num_neg'])\n",
    "\n",
    "    # Training\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                      np.array(labels), # labels\n",
    "                      batch_size=configurations['batch_size'], epochs=1, verbose=0, shuffle=True)\n",
    "    t2 = time()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % configurations['verbose'] == 0:\n",
    "        \n",
    "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "        \n",
    "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "        \n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
    "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "        if hr > best_hr:\n",
    "        \n",
    "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            model_out_file = '%s_GMF_%d.weights.h5' %(configurations['dataset'], configurations['num_factors'])\n",
    "        \n",
    "            if configurations['out'] > 0:\n",
    "                model.save_weights(model_out_file, overwrite=True)\n",
    "        \n",
    "            print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "            \n",
    "if configurations['out'] > 0:\n",
    "    \n",
    "    print(\"The best GMF model is saved to %s\" %(model_out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed24176",
   "metadata": {
    "id": "KAG162orzV69",
    "papermill": {
     "duration": 0.01257,
     "end_time": "2024-04-01T12:37:28.014238",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.001668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc38c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:37:28.040838Z",
     "iopub.status.busy": "2024-04-01T12:37:28.040528Z",
     "iopub.status.idle": "2024-04-01T12:37:28.046693Z",
     "shell.execute_reply": "2024-04-01T12:37:28.045795Z"
    },
    "id": "VmBAKmbYzWn1",
    "outputId": "ecbd1d83-cf25-4004-a268-9a43089c7932",
    "papermill": {
     "duration": 0.02205,
     "end_time": "2024-04-01T12:37:28.048830",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.026780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "path : /kaggle/working/Data/\n",
      "dataset : ml-1m\n",
      "reg_layers : [0, 0, 0]\n",
      "lr : 0.001\n",
      "batch_size : 256\n",
      "epochs : 10\n",
      "learner : adam\n",
      "layers : [32, 16, 8]\n",
      "num_neg : 2\n",
      "verbose : 2\n",
      "out : True\n"
     ]
    }
   ],
   "source": [
    "configurations = {\n",
    "    'path': Path(os.getcwd()) / \"Data\",\n",
    "    'dataset': 'ml-1m',\n",
    "    'reg_layers': [0, 0, 0],\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'epochs': 10,          ## Training Epochs\n",
    "    'learner': 'adam',\n",
    "    'layers': [32, 16, 8],\n",
    "    'num_neg': 2,\n",
    "    'verbose': 2,\n",
    "    'out': True,\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5817a6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:37:28.075480Z",
     "iopub.status.busy": "2024-04-01T12:37:28.075186Z",
     "iopub.status.idle": "2024-04-01T12:37:28.085962Z",
     "shell.execute_reply": "2024-04-01T12:37:28.085235Z"
    },
    "id": "_86GyYTD2sHs",
    "papermill": {
     "duration": 0.026356,
     "end_time": "2024-04-01T12:37:28.087783",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.061427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_MLP_model(num_users, num_items, layers: list[int] = [20,10], reg_layers=[0,0]):\n",
    "    assert len(layers) == len(reg_layers)\n",
    "\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0]//2, name='user_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(reg_layers[0]))(user_input)\n",
    "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=layers[0]//2, name='item_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(reg_layers[1]))(item_input)\n",
    "\n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User)\n",
    "    item_latent = Flatten()(MF_Embedding_Item)\n",
    "\n",
    "    # The 0-th layer is the concatenation of embedding layers\n",
    "    vector = concatenate([user_latent, item_latent])\n",
    "\n",
    "    # MLP layers\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = Dense(units=layers[idx], kernel_regularizer= regularizers.l2(reg_layers[idx]), activation='relu', name = 'layer%d' %idx)\n",
    "        vector = layer(vector)\n",
    "\n",
    "    # Final prediction layer\n",
    "    prediction = Dense(units=1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(vector)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input],\n",
    "                  outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006d30d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:37:28.114651Z",
     "iopub.status.busy": "2024-04-01T12:37:28.114378Z",
     "iopub.status.idle": "2024-04-01T12:37:28.187123Z",
     "shell.execute_reply": "2024-04-01T12:37:28.186326Z"
    },
    "id": "nFKL2FiI3QbD",
    "outputId": "8eb521ba-8f56-430b-ae8f-1eb2198f6a10",
    "papermill": {
     "duration": 0.088541,
     "end_time": "2024-04-01T12:37:28.189255",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.100714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">96,640</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,296</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ layer1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ layer2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m96,640\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m59,296\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ layer1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ layer2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,609</span> (611.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m156,609\u001b[0m (611.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,609</span> (611.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m156,609\u001b[0m (611.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = get_MLP_model(num_users, num_items, configurations['layers'], configurations['reg_layers'])\n",
    "if configurations['learner'].lower() == \"adagrad\":\n",
    "    model.compile(optimizer=Adagrad(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=RMSprop(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"adam\":\n",
    "    model.compile(optimizer=Adam(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "else:\n",
    "    model.compile(optimizer=SGD(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee449fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:37:28.217498Z",
     "iopub.status.busy": "2024-04-01T12:37:28.217203Z",
     "iopub.status.idle": "2024-04-01T12:37:28.220951Z",
     "shell.execute_reply": "2024-04-01T12:37:28.220214Z"
    },
    "id": "fnEvZ2zX3QbE",
    "papermill": {
     "duration": 0.019875,
     "end_time": "2024-04-01T12:37:28.222792",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.202917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d25169a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:37:28.250992Z",
     "iopub.status.busy": "2024-04-01T12:37:28.250723Z",
     "iopub.status.idle": "2024-04-01T12:42:59.516979Z",
     "shell.execute_reply": "2024-04-01T12:42:59.515932Z"
    },
    "id": "kUHRNOBP3QbF",
    "outputId": "a726b935-0f5f-4967-d05e-1bea850de584",
    "papermill": {
     "duration": 331.297244,
     "end_time": "2024-04-01T12:42:59.533632",
     "exception": false,
     "start_time": "2024-04-01T12:37:28.236388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.0952, NDCG = 0.0373\t [331.3 s]\n"
     ]
    }
   ],
   "source": [
    "# Init performance\n",
    "t1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "#mf_embedding_norm = np.linalg.norm(model.get_layer('user_embedding').get_weights())+np.linalg.norm(model.get_layer('item_embedding').get_weights())\n",
    "#p_norm = np.linalg.norm(model.get_layer('prediction').get_weights()[0])\n",
    "print('Init: HR = %.4f, NDCG = %.4f\\t [%.1f s]' % (hr, ndcg, time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95d3f3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T12:42:59.563343Z",
     "iopub.status.busy": "2024-04-01T12:42:59.562665Z",
     "iopub.status.idle": "2024-04-01T13:16:48.715951Z",
     "shell.execute_reply": "2024-04-01T13:16:48.714944Z"
    },
    "id": "5VtM7UQ03QbG",
    "outputId": "6aae11da-30de-4df3-b377-3f0809688700",
    "papermill": {
     "duration": 2029.185791,
     "end_time": "2024-04-01T13:16:48.733296",
     "exception": false,
     "start_time": "2024-04-01T12:42:59.547505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [35.8 s]: HR = 0.4916, NDCG = 0.2658, loss = 0.4386 [330.8 s]\n",
      "End. Best Iteration 0:  HR = 0.4916, NDCG = 0.2658. \n",
      "Iteration 2 [32.9 s]: HR = 0.5601, NDCG = 0.3100, loss = 0.3772 [333.1 s]\n",
      "End. Best Iteration 2:  HR = 0.5601, NDCG = 0.3100. \n",
      "Iteration 4 [32.9 s]: HR = 0.5876, NDCG = 0.3293, loss = 0.3519 [334.9 s]\n",
      "End. Best Iteration 4:  HR = 0.5876, NDCG = 0.3293. \n",
      "Iteration 6 [33.6 s]: HR = 0.6053, NDCG = 0.3414, loss = 0.3407 [335.8 s]\n",
      "End. Best Iteration 6:  HR = 0.6053, NDCG = 0.3414. \n",
      "Iteration 8 [33.5 s]: HR = 0.6180, NDCG = 0.3513, loss = 0.3342 [359.2 s]\n",
      "End. Best Iteration 8:  HR = 0.6180, NDCG = 0.3513. \n",
      "The best MLP model is saved to ml-1m_MLP_[32, 16, 8].weights.h5\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "for epoch in range(configurations['epochs']):\n",
    "    t1 = time()\n",
    "    # Generate training instances\n",
    "    user_input, item_input, labels = get_train_instances(train, configurations['num_neg'])\n",
    "\n",
    "    # Training\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                      np.array(labels), # labels\n",
    "                      batch_size=configurations['batch_size'], epochs=1, verbose=0, shuffle=True)\n",
    "    t2 = time()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % configurations['verbose'] == 0:\n",
    "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
    "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        if hr > best_hr:\n",
    "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            model_out_file = '%s_MLP_%s.weights.h5' %(configurations['dataset'], configurations['layers'])\n",
    "            if configurations['out'] > 0:\n",
    "                model.save_weights(model_out_file, overwrite=True)\n",
    "            print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "if configurations['out'] > 0:\n",
    "    print(\"The best MLP model is saved to %s\" %(model_out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6afcd",
   "metadata": {
    "id": "QZw9Cwxj3QbG",
    "papermill": {
     "duration": 0.014014,
     "end_time": "2024-04-01T13:16:48.761944",
     "exception": false,
     "start_time": "2024-04-01T13:16:48.747930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f9340b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:16:48.792921Z",
     "iopub.status.busy": "2024-04-01T13:16:48.792555Z",
     "iopub.status.idle": "2024-04-01T13:16:48.799577Z",
     "shell.execute_reply": "2024-04-01T13:16:48.798680Z"
    },
    "id": "miktyXx38_uy",
    "outputId": "f8fc1739-7680-4136-a909-40f618b31c38",
    "papermill": {
     "duration": 0.025523,
     "end_time": "2024-04-01T13:16:48.801941",
     "exception": false,
     "start_time": "2024-04-01T13:16:48.776418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "path : /kaggle/working/Data/\n",
      "dataset : ml-1m\n",
      "epochs : 10\n",
      "batch_size : 256\n",
      "num_factors : 10\n",
      "layers : [32, 16, 8]\n",
      "reg_mf : 0\n",
      "reg_layers : [0, 0, 0]\n",
      "num_neg : 2\n",
      "lr : 0.001\n",
      "learner : adam\n",
      "verbose : 2\n",
      "out : True\n",
      "mf_pretrain : \n",
      "mlp_pretrain : \n"
     ]
    }
   ],
   "source": [
    "configurations = {\n",
    "    'path': '/kaggle/working/Data/',\n",
    "    'dataset': 'ml-1m',\n",
    "    'epochs': 10,          ## Training Epochs\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'num_factors': 10,\n",
    "    'layers': [32, 16, 8],\n",
    "    'reg_mf': 0,\n",
    "    'reg_layers': [0, 0, 0],\n",
    "    'num_neg': 2,\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'learner': 'adam',\n",
    "    'verbose': 2,\n",
    "    'out': True,\n",
    "    'mf_pretrain': '',\n",
    "    'mlp_pretrain': ''\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de5cf894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:16:48.833087Z",
     "iopub.status.busy": "2024-04-01T13:16:48.832762Z",
     "iopub.status.idle": "2024-04-01T13:16:48.846536Z",
     "shell.execute_reply": "2024-04-01T13:16:48.845628Z"
    },
    "id": "zhhjHvDM-IdG",
    "papermill": {
     "duration": 0.031917,
     "end_time": "2024-04-01T13:16:48.848585",
     "exception": false,
     "start_time": "2024-04-01T13:16:48.816668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_NeuMF_model(num_users, num_items, mf_dim=10, layers=[10], reg_layers=[0], reg_mf=0):\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = keras.Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    # Embedding layer\n",
    "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = mf_dim, name = 'mf_embedding_user',\n",
    "                                  embeddings_initializer=keras.initializers.RandomNormal(stddev=0.01), embeddings_regularizer = keras.regularizers.l2(reg_mf))(user_input)\n",
    "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = mf_dim, name = 'mf_embedding_item',\n",
    "                                  embeddings_initializer=keras.initializers.RandomNormal(stddev=0.01), embeddings_regularizer = keras.regularizers.l2(reg_mf))(item_input)\n",
    "\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = layers[0]//2, name = \"mlp_embedding_user\",\n",
    "                                  embeddings_initializer=keras.initializers.RandomNormal(stddev=0.01), embeddings_regularizer = keras.regularizers.l2(reg_layers[0]))(user_input)\n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = layers[0]//2, name = 'mlp_embedding_item',\n",
    "                                  embeddings_initializer=keras.initializers.RandomNormal(stddev=0.01), embeddings_regularizer = keras.regularizers.l2(reg_layers[0]))(item_input)\n",
    "\n",
    "    # MF part\n",
    "    mf_user_latent = Flatten()(MF_Embedding_User)\n",
    "    mf_item_latent = Flatten()(MF_Embedding_Item)\n",
    "    mf_vector = multiply([mf_user_latent, mf_item_latent]) # element-wise multiply\n",
    "\n",
    "    # MLP part\n",
    "    mlp_user_latent = Flatten()(MLP_Embedding_User)\n",
    "    mlp_item_latent = Flatten()(MLP_Embedding_Item)\n",
    "    mlp_vector = concatenate([mlp_user_latent, mlp_item_latent])\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = Dense(units=layers[idx], kernel_regularizer= keras.regularizers.l2(reg_layers[idx]), activation='relu', name=\"layer%d\" %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    # Concatenate \n",
    "    #mf_vector = Lambda(lambda x: x * alpha)(mf_vector)\n",
    "    #mlp_vector = Lambda(lambda x : x * (1-alpha))(mlp_vector)\n",
    "        \n",
    "    \n",
    "    predict_vector = concatenate([mf_vector, mlp_vector])\n",
    "\n",
    "    # Final prediction layer\n",
    "    prediction = Dense(units=1, activation='sigmoid', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input],\n",
    "                  outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ea856fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:16:48.879763Z",
     "iopub.status.busy": "2024-04-01T13:16:48.879437Z",
     "iopub.status.idle": "2024-04-01T13:16:49.045269Z",
     "shell.execute_reply": "2024-04-01T13:16:49.044324Z"
    },
    "id": "0FGKnCK6J0jb",
    "outputId": "1f9545dc-5348-40e2-8d1f-8c84d5b80d2a",
    "papermill": {
     "duration": 0.184691,
     "end_time": "2024-04-01T13:16:49.048039",
     "exception": false,
     "start_time": "2024-04-01T13:16:48.863348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding_user  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">96,640</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding_item  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,296</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp_embedding_us… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mlp_embedding_it… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mf_embedding_user   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mf_embedding_item   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,060</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mf_embedding_use… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mf_embedding_ite… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │ layer1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ layer2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding_user  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m96,640\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlp_embedding_item  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m59,296\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mlp_embedding_us… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mlp_embedding_it… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mf_embedding_user   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m60,400\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mf_embedding_item   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m37,060\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mf_embedding_use… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ mf_embedding_ite… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer2 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m136\u001b[0m │ layer1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ layer2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m19\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,079</span> (992.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m254,079\u001b[0m (992.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,079</span> (992.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m254,079\u001b[0m (992.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = get_NeuMF_model(num_users, num_items, configurations['num_factors'], configurations['layers'], configurations['reg_layers'], configurations['reg_mf'])\n",
    "if configurations['learner'].lower() == \"adagrad\":\n",
    "    model.compile(optimizer=Adagrad(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=RMSprop(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"adam\":\n",
    "    model.compile(optimizer=Adam(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "else:\n",
    "    model.compile(optimizer=SGD(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "546f3287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:16:49.081054Z",
     "iopub.status.busy": "2024-04-01T13:16:49.080753Z",
     "iopub.status.idle": "2024-04-01T13:16:49.084973Z",
     "shell.execute_reply": "2024-04-01T13:16:49.084055Z"
    },
    "id": "uj6ynL-zJ0jb",
    "papermill": {
     "duration": 0.023164,
     "end_time": "2024-04-01T13:16:49.087121",
     "exception": false,
     "start_time": "2024-04-01T13:16:49.063957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff4440c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:16:49.120356Z",
     "iopub.status.busy": "2024-04-01T13:16:49.119990Z",
     "iopub.status.idle": "2024-04-01T13:22:50.928645Z",
     "shell.execute_reply": "2024-04-01T13:22:50.927605Z"
    },
    "id": "ilL7qxIjJ0jb",
    "outputId": "4e66189c-7fa0-4d0e-a765-dbf45b4af7e1",
    "papermill": {
     "duration": 361.844293,
     "end_time": "2024-04-01T13:22:50.947131",
     "exception": false,
     "start_time": "2024-04-01T13:16:49.102838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.0960, NDCG = 0.0438\t [361.8 s]\n"
     ]
    }
   ],
   "source": [
    "# Init performance\n",
    "t1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "#mf_embedding_norm = np.linalg.norm(model.get_layer('user_embedding').get_weights())+np.linalg.norm(model.get_layer('item_embedding').get_weights())\n",
    "#p_norm = np.linalg.norm(model.get_layer('prediction').get_weights()[0])\n",
    "print('Init: HR = %.4f, NDCG = %.4f\\t [%.1f s]' % (hr, ndcg, time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d9abae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T13:22:50.980266Z",
     "iopub.status.busy": "2024-04-01T13:22:50.979911Z",
     "iopub.status.idle": "2024-04-01T13:59:47.545022Z",
     "shell.execute_reply": "2024-04-01T13:59:47.543955Z"
    },
    "id": "WdkBraQZAxN3",
    "outputId": "6b9a2ca6-c660-414e-9c76-be1a7f43008e",
    "papermill": {
     "duration": 2216.602583,
     "end_time": "2024-04-01T13:59:47.565613",
     "exception": false,
     "start_time": "2024-04-01T13:22:50.963030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NeuMF for 10 epochs\n",
      "Iteration 2 [39.0 s]: HR = 0.6215, NDCG = 0.3529, loss = 0.3395 [363.9 s]\n",
      "End. Best Iteration 2:  HR = 0.6215, NDCG = 0.3529. \n",
      "Iteration 4 [38.8 s]: HR = 0.6535, NDCG = 0.3800, loss = 0.3150 [367.2 s]\n",
      "End. Best Iteration 4:  HR = 0.6535, NDCG = 0.3800. \n",
      "Iteration 6 [38.8 s]: HR = 0.6677, NDCG = 0.3913, loss = 0.3066 [365.2 s]\n",
      "End. Best Iteration 6:  HR = 0.6677, NDCG = 0.3913. \n",
      "Iteration 8 [38.7 s]: HR = 0.6664, NDCG = 0.3949, loss = 0.3021 [360.3 s]\n",
      "Iteration 10 [38.5 s]: HR = 0.6719, NDCG = 0.3946, loss = 0.2979 [368.3 s]\n",
      "End. Best Iteration 10:  HR = 0.6719, NDCG = 0.3946. \n",
      "The best NeuMF model is saved to ml-1m_NeuMF_10_[32, 16, 8].weights.h5\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(f\"Training NeuMF for {configurations['epochs']} epochs\")\n",
    "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "for epoch in range(1, configurations['epochs']+1):\n",
    "    t1 = time()\n",
    "    # Generate training instances\n",
    "    user_input, item_input, labels = get_train_instances(train, configurations['num_neg'])\n",
    "\n",
    "    # Training\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                      np.array(labels), # labels\n",
    "                      batch_size=configurations['batch_size'], epochs=1, verbose=0, shuffle=True)\n",
    "    t2 = time()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % configurations['verbose'] == 0:\n",
    "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
    "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        if hr > best_hr:\n",
    "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            model_out_file = '%s_NeuMF_%d_%s.weights.h5' %(configurations['dataset'], configurations['num_factors'],configurations['layers'])\n",
    "            if configurations['out'] > 0:\n",
    "                model.save_weights(model_out_file, overwrite=True)\n",
    "            print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "if configurations['out'] > 0:\n",
    "    print(\"The best NeuMF model is saved to %s\" %(model_out_file))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "N9H4tLezzhOJ",
    "csXwN9cl2U1-",
    "BN5AgtadzTlI"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ncf-recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7311.29697,
   "end_time": "2024-04-01T13:59:50.617724",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-01T11:57:59.320754",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
