{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b008ff09",
   "metadata": {},
   "source": [
    "# Code By Dhruv Panchal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7c3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, os\n",
    "import logging\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86771f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhruv\\\\Documents\\\\DA-IICT\\\\Arpit_rana\\\\MajorProject'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d2f25",
   "metadata": {},
   "source": [
    "## let's Start by loading the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64cec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e11f87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFTrainDataset(Dataset):\n",
    "    def __init__(self, train_csv, num_negatives=4, num_items=0):\n",
    "        \n",
    "        self.train_df = pd.read_csv(train_csv)\n",
    "        self.user_item_set = set(zip(self.train_df[\"UserID\"],self.train_df[\"ItemID\"]))\n",
    "        \n",
    "        self.num_items = max(num_items, max(self.train_df[\"ItemID\"])+1)\n",
    "        \n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        self.users, self.items, self.labels = self._get_train_instances()\n",
    "        \n",
    "    def _get_train_instances(self):\n",
    "         \n",
    "        user_input, item_input, labels = [], [], []\n",
    "         \n",
    "        for (u, i) in self.user_item_set:\n",
    "            # positive instance\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            labels.append(1)\n",
    "            \n",
    "            # negative instances\n",
    "            \n",
    "            for _ in range(self.num_negatives):\n",
    "            \n",
    "                j = np.random.randint(self.num_items)\n",
    "            \n",
    "                while (u, j) in self.user_item_set:\n",
    "            \n",
    "                    j = np.random.randint(self.num_items)\n",
    "            \n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                labels.append(0)\n",
    "                \n",
    "        return user_input, item_input, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.users[idx], dtype=torch.long), torch.tensor(self.items[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6a5126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_object = NCFTrainDataset(r\"NCF_Pytorch\\train_data.csv\", num_negatives=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "047ca370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x143cfa830b0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_object_loader = DataLoader(test_train_object, batch_size=32, shuffle=False)\n",
    "\n",
    "test_train_object_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c95cd33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155339"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_train_object_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "77daf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Batches are : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "89f8c57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*__*\n",
      "0\n",
      "users shape: torch.Size([32])\n",
      "users: tensor([ 476,  476,  476,  476,  476, 4385, 4385, 4385, 4385, 4385, 2236, 2236,\n",
      "        2236, 2236, 2236,  498,  498,  498,  498,  498,   35,   35,   35,   35,\n",
      "          35, 5004, 5004, 5004, 5004, 5004, 3944, 3944])\n",
      "items shape: torch.Size([32])\n",
      "items: tensor([  78, 1496,  981,  827, 3098,  413, 3294, 2598,  862, 1796,  469, 3476,\n",
      "         599,  887, 2655, 1557,  477, 2881, 2737, 2539,  335, 2877, 1754, 2201,\n",
      "         360,  650, 2464, 3703, 1430, 1293,  670, 2659])\n",
      "labels shape: torch.Size([32])\n",
      "labels: tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for index, batch in enumerate(test_train_object_loader):\n",
    "    print(\"__*\"*50)\n",
    "    print(index)\n",
    "    user, item, label = batch\n",
    "    \n",
    "    print(f\"users shape: {user.shape}\")\n",
    "    print(f\"users: {user}\")\n",
    "    print(f\"items shape: {item.shape}\")\n",
    "    print(f\"items: {item}\")\n",
    "    print(f\"labels shape: {label.shape}\")\n",
    "    print(f\"labels: {label}\")\n",
    "    \n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5cbda226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78,\n",
       " 1496,\n",
       " 981,\n",
       " 827,\n",
       " 3098,\n",
       " 413,\n",
       " 3294,\n",
       " 2598,\n",
       " 862,\n",
       " 1796,\n",
       " 469,\n",
       " 3476,\n",
       " 599,\n",
       " 887,\n",
       " 2655,\n",
       " 1557,\n",
       " 477,\n",
       " 2881,\n",
       " 2737,\n",
       " 2539,\n",
       " 335,\n",
       " 2877,\n",
       " 1754,\n",
       " 2201,\n",
       " 360,\n",
       " 650,\n",
       " 2464,\n",
       " 3703,\n",
       " 1430,\n",
       " 1293,\n",
       " 670,\n",
       " 2659,\n",
       " 1939,\n",
       " 1942,\n",
       " 2169,\n",
       " 255,\n",
       " 1769,\n",
       " 2811,\n",
       " 1815,\n",
       " 3698,\n",
       " 1018,\n",
       " 3543,\n",
       " 958,\n",
       " 3529,\n",
       " 3528,\n",
       " 504,\n",
       " 3125,\n",
       " 1629,\n",
       " 2638,\n",
       " 3407,\n",
       " 338,\n",
       " 3417,\n",
       " 1943,\n",
       " 823,\n",
       " 706,\n",
       " 946,\n",
       " 3590,\n",
       " 1578,\n",
       " 3280,\n",
       " 3681,\n",
       " 432,\n",
       " 1173,\n",
       " 2332,\n",
       " 2669,\n",
       " 2829,\n",
       " 1163,\n",
       " 461,\n",
       " 1764,\n",
       " 1601,\n",
       " 1503,\n",
       " 1010,\n",
       " 3648,\n",
       " 3511,\n",
       " 257,\n",
       " 867,\n",
       " 609,\n",
       " 2548,\n",
       " 2160,\n",
       " 874,\n",
       " 3505,\n",
       " 689,\n",
       " 2089,\n",
       " 3634,\n",
       " 3531,\n",
       " 308,\n",
       " 155,\n",
       " 663,\n",
       " 2177,\n",
       " 1773,\n",
       " 2886,\n",
       " 2779,\n",
       " 1796,\n",
       " 2357,\n",
       " 1068,\n",
       " 2049,\n",
       " 274,\n",
       " 1236,\n",
       " 2493,\n",
       " 3453,\n",
       " 3451,\n",
       " 146,\n",
       " 456,\n",
       " 1422,\n",
       " 853,\n",
       " 2278,\n",
       " 2083,\n",
       " 3442,\n",
       " 108,\n",
       " 2996,\n",
       " 2972,\n",
       " 2103,\n",
       " 3150,\n",
       " 2880,\n",
       " 899,\n",
       " 21,\n",
       " 340,\n",
       " 2800,\n",
       " 3216,\n",
       " 2823,\n",
       " 1729,\n",
       " 1091,\n",
       " 3558,\n",
       " 2673,\n",
       " 3294,\n",
       " 2664,\n",
       " 766,\n",
       " 1411,\n",
       " 3407,\n",
       " 1777,\n",
       " 1542,\n",
       " 676,\n",
       " 2533,\n",
       " 3163,\n",
       " 3167,\n",
       " 1881,\n",
       " 1230,\n",
       " 843,\n",
       " 1983,\n",
       " 199,\n",
       " 1583,\n",
       " 604,\n",
       " 2649,\n",
       " 2956,\n",
       " 1717,\n",
       " 825,\n",
       " 90,\n",
       " 3043,\n",
       " 2099,\n",
       " 1958,\n",
       " 3436,\n",
       " 70,\n",
       " 2795,\n",
       " 1740,\n",
       " 2832,\n",
       " 639,\n",
       " 877,\n",
       " 3269,\n",
       " 2215,\n",
       " 2694,\n",
       " 2438,\n",
       " 18,\n",
       " 2900,\n",
       " 1443,\n",
       " 602,\n",
       " 2930,\n",
       " 38,\n",
       " 3290,\n",
       " 3185,\n",
       " 2096,\n",
       " 1567,\n",
       " 711,\n",
       " 2605,\n",
       " 2671,\n",
       " 1233,\n",
       " 1689,\n",
       " 366,\n",
       " 812,\n",
       " 1571,\n",
       " 580,\n",
       " 783,\n",
       " 753,\n",
       " 3048,\n",
       " 3259,\n",
       " 1623,\n",
       " 1426,\n",
       " 219,\n",
       " 1492,\n",
       " 2413,\n",
       " 1212,\n",
       " 3311,\n",
       " 1383,\n",
       " 3156,\n",
       " 1837,\n",
       " 160,\n",
       " 260,\n",
       " 701,\n",
       " 310,\n",
       " 963,\n",
       " 2130,\n",
       " 1790,\n",
       " 358,\n",
       " 978,\n",
       " 1504,\n",
       " 2718,\n",
       " 3099,\n",
       " 1845,\n",
       " 2983,\n",
       " 2786,\n",
       " 208,\n",
       " 1087,\n",
       " 89,\n",
       " 776,\n",
       " 3173,\n",
       " 0,\n",
       " 1510,\n",
       " 2251,\n",
       " 777,\n",
       " 3139,\n",
       " 2471,\n",
       " 2189,\n",
       " 1259,\n",
       " 2550,\n",
       " 378,\n",
       " 144,\n",
       " 1944,\n",
       " 2524,\n",
       " 21,\n",
       " 2385,\n",
       " 3559,\n",
       " 160,\n",
       " 2943,\n",
       " 2778,\n",
       " 1211,\n",
       " 1667,\n",
       " 3594,\n",
       " 1911,\n",
       " 927,\n",
       " 1971,\n",
       " 541,\n",
       " 2938,\n",
       " 1097,\n",
       " 1325,\n",
       " 1480,\n",
       " 1733,\n",
       " 3454,\n",
       " 1115,\n",
       " 3015,\n",
       " 1793,\n",
       " 2819,\n",
       " 1227,\n",
       " 491,\n",
       " 109,\n",
       " 1830,\n",
       " 1534,\n",
       " 2325,\n",
       " 567,\n",
       " 2999,\n",
       " 3582,\n",
       " 405,\n",
       " 1235,\n",
       " 1298,\n",
       " 2258,\n",
       " 1434,\n",
       " 3453,\n",
       " 2841,\n",
       " 973,\n",
       " 2461,\n",
       " 1215,\n",
       " 296,\n",
       " 3344,\n",
       " 305,\n",
       " 595,\n",
       " 3061,\n",
       " 3448,\n",
       " 2628,\n",
       " 325,\n",
       " 3246,\n",
       " 1857,\n",
       " 3619,\n",
       " 2700,\n",
       " 44,\n",
       " 660,\n",
       " 3182,\n",
       " 724,\n",
       " 3589,\n",
       " 1517,\n",
       " 2610,\n",
       " 1054,\n",
       " 3069,\n",
       " 2388,\n",
       " 727,\n",
       " 2896,\n",
       " 1190,\n",
       " 3027,\n",
       " 2459,\n",
       " 711,\n",
       " 407,\n",
       " 2712,\n",
       " 3560,\n",
       " 1351,\n",
       " 197,\n",
       " 3478,\n",
       " 238,\n",
       " 3539,\n",
       " 2257,\n",
       " 177,\n",
       " 476,\n",
       " 3277,\n",
       " 2973,\n",
       " 1609,\n",
       " 316,\n",
       " 1485,\n",
       " 502,\n",
       " 2172,\n",
       " 2588,\n",
       " 1185,\n",
       " 3065,\n",
       " 2964,\n",
       " 2756,\n",
       " 998,\n",
       " 651,\n",
       " 2192,\n",
       " 1700,\n",
       " 694,\n",
       " 511,\n",
       " 59,\n",
       " 110,\n",
       " 2721,\n",
       " 1529,\n",
       " 3292,\n",
       " 1189,\n",
       " 3036,\n",
       " 974,\n",
       " 3381,\n",
       " 1263,\n",
       " 1231,\n",
       " 2417,\n",
       " 2070,\n",
       " 3152,\n",
       " 687,\n",
       " 1061,\n",
       " 14,\n",
       " 1844,\n",
       " 3021,\n",
       " 980,\n",
       " 527,\n",
       " 1923,\n",
       " 1225,\n",
       " 2308,\n",
       " 1071,\n",
       " 184,\n",
       " 181,\n",
       " 2216,\n",
       " 442,\n",
       " 330,\n",
       " 258,\n",
       " 1178,\n",
       " 2614,\n",
       " 2643,\n",
       " 2420,\n",
       " 587,\n",
       " 3117,\n",
       " 3063,\n",
       " 927,\n",
       " 1841,\n",
       " 788,\n",
       " 1708,\n",
       " 2947,\n",
       " 2342,\n",
       " 411,\n",
       " 44,\n",
       " 1632,\n",
       " 2056,\n",
       " 2411,\n",
       " 2217,\n",
       " 1270,\n",
       " 3191,\n",
       " 2319,\n",
       " 3170,\n",
       " 1543,\n",
       " 245,\n",
       " 280,\n",
       " 1067,\n",
       " 2139,\n",
       " 1960,\n",
       " 1076,\n",
       " 2109,\n",
       " 1960,\n",
       " 3243,\n",
       " 2689,\n",
       " 352,\n",
       " 1742,\n",
       " 2566,\n",
       " 1705,\n",
       " 3507,\n",
       " 388,\n",
       " 1035,\n",
       " 1056,\n",
       " 1836,\n",
       " 1031,\n",
       " 332,\n",
       " 1552,\n",
       " 3593,\n",
       " 2916,\n",
       " 2156,\n",
       " 814,\n",
       " 2693,\n",
       " 1661,\n",
       " 1534,\n",
       " 2204,\n",
       " 127,\n",
       " 1015,\n",
       " 2946,\n",
       " 1808,\n",
       " 3231,\n",
       " 75,\n",
       " 3227,\n",
       " 561,\n",
       " 268,\n",
       " 678,\n",
       " 1185,\n",
       " 693,\n",
       " 3001,\n",
       " 293,\n",
       " 3036,\n",
       " 461,\n",
       " 1012,\n",
       " 1704,\n",
       " 1728,\n",
       " 2918,\n",
       " 59,\n",
       " 1557,\n",
       " 2369,\n",
       " 1530,\n",
       " 70,\n",
       " 655,\n",
       " 217,\n",
       " 2870,\n",
       " 1926,\n",
       " 527,\n",
       " 256,\n",
       " 3206,\n",
       " 3225,\n",
       " 257,\n",
       " 2864,\n",
       " 142,\n",
       " 71,\n",
       " 1655,\n",
       " 1232,\n",
       " 24,\n",
       " 132,\n",
       " 2359,\n",
       " 1249,\n",
       " 1250,\n",
       " 1278,\n",
       " 742,\n",
       " 2751,\n",
       " 3023,\n",
       " 2987,\n",
       " 1816,\n",
       " 18,\n",
       " 3602,\n",
       " 1372,\n",
       " 1096,\n",
       " 1022,\n",
       " 596,\n",
       " 3047,\n",
       " 3261,\n",
       " 1471,\n",
       " 1923,\n",
       " 3022,\n",
       " 2622,\n",
       " 2551,\n",
       " 2875,\n",
       " 2715,\n",
       " 690,\n",
       " 3397,\n",
       " 1545,\n",
       " 1005,\n",
       " 153,\n",
       " 881,\n",
       " 1774,\n",
       " 2818,\n",
       " 2633,\n",
       " 2475,\n",
       " 733,\n",
       " 3625,\n",
       " 2880,\n",
       " 1817,\n",
       " 3336,\n",
       " 753,\n",
       " 1447,\n",
       " 2288,\n",
       " 2223,\n",
       " 1382,\n",
       " 66,\n",
       " 3652,\n",
       " 1707,\n",
       " 3186,\n",
       " 3358,\n",
       " 2571,\n",
       " 3580,\n",
       " 1757,\n",
       " 1654,\n",
       " 2018,\n",
       " 1405,\n",
       " 157,\n",
       " 1624,\n",
       " 2101,\n",
       " 1435,\n",
       " 528,\n",
       " 150,\n",
       " 2524,\n",
       " 3533,\n",
       " 1834,\n",
       " 14,\n",
       " 2806,\n",
       " 2352,\n",
       " 832,\n",
       " 3469,\n",
       " 2555,\n",
       " 1756,\n",
       " 2640,\n",
       " 3494,\n",
       " 856,\n",
       " 2385,\n",
       " 727,\n",
       " 744,\n",
       " 2982,\n",
       " 2744,\n",
       " 77,\n",
       " 3024,\n",
       " 2518,\n",
       " 1387,\n",
       " 2233,\n",
       " 2694,\n",
       " 2050,\n",
       " 2362,\n",
       " 3270,\n",
       " 1893,\n",
       " 2032,\n",
       " 822,\n",
       " 2943,\n",
       " 2056,\n",
       " 3540,\n",
       " 2433,\n",
       " 153,\n",
       " 3463,\n",
       " 1137,\n",
       " 661,\n",
       " 81,\n",
       " 3241,\n",
       " 3203,\n",
       " 3352,\n",
       " 912,\n",
       " 123,\n",
       " 3374,\n",
       " 544,\n",
       " 2512,\n",
       " 2800,\n",
       " 127,\n",
       " 2882,\n",
       " 1373,\n",
       " 2763,\n",
       " 2880,\n",
       " 210,\n",
       " 225,\n",
       " 1590,\n",
       " 3640,\n",
       " 2724,\n",
       " 629,\n",
       " 3195,\n",
       " 2937,\n",
       " 1391,\n",
       " 1344,\n",
       " 1569,\n",
       " 827,\n",
       " 2137,\n",
       " 1923,\n",
       " 762,\n",
       " 672,\n",
       " 2631,\n",
       " 297,\n",
       " 1260,\n",
       " 2955,\n",
       " 1091,\n",
       " 1624,\n",
       " 1295,\n",
       " 1096,\n",
       " 2946,\n",
       " 640,\n",
       " 818,\n",
       " 1685,\n",
       " 2945,\n",
       " 1750,\n",
       " 359,\n",
       " 1722,\n",
       " 3492,\n",
       " 2515,\n",
       " 2373,\n",
       " 2099,\n",
       " 3045,\n",
       " 2533,\n",
       " 318,\n",
       " 3573,\n",
       " 0,\n",
       " 1627,\n",
       " 138,\n",
       " 1517,\n",
       " 3338,\n",
       " 762,\n",
       " 1863,\n",
       " 3103,\n",
       " 1076,\n",
       " 2719,\n",
       " 1106,\n",
       " 2358,\n",
       " 1910,\n",
       " 1209,\n",
       " 2297,\n",
       " 640,\n",
       " 1572,\n",
       " 3538,\n",
       " 2441,\n",
       " 2491,\n",
       " 450,\n",
       " 1639,\n",
       " 3170,\n",
       " 3477,\n",
       " 2750,\n",
       " 97,\n",
       " 1458,\n",
       " 2900,\n",
       " 481,\n",
       " 1891,\n",
       " 2104,\n",
       " 2065,\n",
       " 883,\n",
       " 427,\n",
       " 1125,\n",
       " 1584,\n",
       " 3502,\n",
       " 2414,\n",
       " 2513,\n",
       " 3107,\n",
       " 2180,\n",
       " 1890,\n",
       " 2578,\n",
       " 2046,\n",
       " 2639,\n",
       " 2734,\n",
       " 55,\n",
       " 2800,\n",
       " 3533,\n",
       " 700,\n",
       " 2524,\n",
       " 97,\n",
       " 2542,\n",
       " 3316,\n",
       " 1261,\n",
       " 559,\n",
       " 1916,\n",
       " 3150,\n",
       " 1977,\n",
       " 687,\n",
       " 1781,\n",
       " 3535,\n",
       " 801,\n",
       " 1928,\n",
       " 2199,\n",
       " 773,\n",
       " 2538,\n",
       " 1435,\n",
       " 438,\n",
       " 532,\n",
       " 240,\n",
       " 230,\n",
       " 2335,\n",
       " 2177,\n",
       " 1369,\n",
       " 701,\n",
       " 832,\n",
       " 477,\n",
       " 2506,\n",
       " 1963,\n",
       " 1338,\n",
       " 3019,\n",
       " 1768,\n",
       " 3337,\n",
       " 2413,\n",
       " 1724,\n",
       " 991,\n",
       " 3228,\n",
       " 3357,\n",
       " 2553,\n",
       " 178,\n",
       " 3218,\n",
       " 1734,\n",
       " 3471,\n",
       " 1681,\n",
       " 732,\n",
       " 3287,\n",
       " 728,\n",
       " 1379,\n",
       " 2949,\n",
       " 768,\n",
       " 1287,\n",
       " 1894,\n",
       " 3084,\n",
       " 2295,\n",
       " 44,\n",
       " 1689,\n",
       " 1945,\n",
       " 2687,\n",
       " 3548,\n",
       " 369,\n",
       " 3257,\n",
       " 2378,\n",
       " 2844,\n",
       " 2673,\n",
       " 507,\n",
       " 1905,\n",
       " 592,\n",
       " 1552,\n",
       " 161,\n",
       " 642,\n",
       " 426,\n",
       " 2310,\n",
       " 1215,\n",
       " 2264,\n",
       " 431,\n",
       " 2727,\n",
       " 467,\n",
       " 3652,\n",
       " 2167,\n",
       " 1523,\n",
       " 618,\n",
       " 323,\n",
       " 1903,\n",
       " 2436,\n",
       " 112,\n",
       " 3298,\n",
       " 2886,\n",
       " 3384,\n",
       " 3518,\n",
       " 865,\n",
       " 1811,\n",
       " 2551,\n",
       " 1110,\n",
       " 3700,\n",
       " 522,\n",
       " 1669,\n",
       " 2335,\n",
       " 700,\n",
       " 3589,\n",
       " 179,\n",
       " 3262,\n",
       " 3547,\n",
       " 1541,\n",
       " 1714,\n",
       " 1672,\n",
       " 2524,\n",
       " 3061,\n",
       " 2050,\n",
       " 2481,\n",
       " 2802,\n",
       " 3175,\n",
       " 1952,\n",
       " 2843,\n",
       " 942,\n",
       " 1194,\n",
       " 3539,\n",
       " 2531,\n",
       " 2767,\n",
       " 1655,\n",
       " 127,\n",
       " 2312,\n",
       " 2398,\n",
       " 709,\n",
       " 3566,\n",
       " 2387,\n",
       " 1860,\n",
       " 2808,\n",
       " 2396,\n",
       " 2938,\n",
       " 1466,\n",
       " 105,\n",
       " 1666,\n",
       " 3095,\n",
       " 2254,\n",
       " 932,\n",
       " 1647,\n",
       " 1286,\n",
       " 1531,\n",
       " 2536,\n",
       " 245,\n",
       " 1191,\n",
       " 2121,\n",
       " 3449,\n",
       " 3631,\n",
       " 2335,\n",
       " 474,\n",
       " 837,\n",
       " 3224,\n",
       " 122,\n",
       " 714,\n",
       " 1425,\n",
       " 1513,\n",
       " 3340,\n",
       " 2014,\n",
       " 872,\n",
       " 2487,\n",
       " 3369,\n",
       " 1770,\n",
       " 1634,\n",
       " 1061,\n",
       " 2357,\n",
       " 730,\n",
       " 2117,\n",
       " 2814,\n",
       " 374,\n",
       " 1028,\n",
       " 2688,\n",
       " 3168,\n",
       " 3371,\n",
       " 738,\n",
       " 1807,\n",
       " 1824,\n",
       " 692,\n",
       " 2548,\n",
       " 1334,\n",
       " 1757,\n",
       " 1738,\n",
       " 1019,\n",
       " 2821,\n",
       " 1354,\n",
       " 674,\n",
       " 2770,\n",
       " 2928,\n",
       " 2448,\n",
       " 647,\n",
       " 2198,\n",
       " 2073,\n",
       " 1404,\n",
       " 3183,\n",
       " 385,\n",
       " 2569,\n",
       " 2691,\n",
       " 2129,\n",
       " 370,\n",
       " 1338,\n",
       " 3561,\n",
       " 3649,\n",
       " 1817,\n",
       " 2549,\n",
       " 2187,\n",
       " 3480,\n",
       " 3127,\n",
       " 3121,\n",
       " 1407,\n",
       " 2531,\n",
       " 1746,\n",
       " 3115,\n",
       " 1690,\n",
       " 353,\n",
       " 923,\n",
       " 3030,\n",
       " 667,\n",
       " 398,\n",
       " 3469,\n",
       " 1477,\n",
       " 2810,\n",
       " 2421,\n",
       " 3086,\n",
       " 3700,\n",
       " 871,\n",
       " 590,\n",
       " 1844,\n",
       " 1861,\n",
       " 3704,\n",
       " 590,\n",
       " 2489,\n",
       " 223,\n",
       " 2331,\n",
       " 944,\n",
       " 954,\n",
       " 384,\n",
       " 905,\n",
       " 2759,\n",
       " 690,\n",
       " 666,\n",
       " 992,\n",
       " 1995,\n",
       " 2102,\n",
       " 3355,\n",
       " 538,\n",
       " 15,\n",
       " 1538,\n",
       " 1550,\n",
       " 2403,\n",
       " 1092,\n",
       " 1722,\n",
       " 2577,\n",
       " 1718,\n",
       " 2912,\n",
       " 661,\n",
       " 1738,\n",
       " 2752,\n",
       " 2010,\n",
       " 1244,\n",
       " 127,\n",
       " 1877,\n",
       " 1607,\n",
       " 1726,\n",
       " 2474,\n",
       " 189,\n",
       " 2622,\n",
       " 2036,\n",
       " 387,\n",
       " 1697,\n",
       " 1412,\n",
       " 1666,\n",
       " 848,\n",
       " 932,\n",
       " 1644,\n",
       " 5,\n",
       " 2826,\n",
       " 2354,\n",
       " 2074,\n",
       " 1803,\n",
       " 1344,\n",
       " 3126,\n",
       " 175,\n",
       " 1358,\n",
       " 868,\n",
       " 276,\n",
       " 2874,\n",
       " 3344,\n",
       " 2989,\n",
       " 1860,\n",
       " 1426,\n",
       " 2518,\n",
       " 1485,\n",
       " 2039,\n",
       " 2665,\n",
       " 529,\n",
       " 914,\n",
       " 487,\n",
       " 2841,\n",
       " 1952,\n",
       " 204,\n",
       " 1551,\n",
       " 298,\n",
       " 1985,\n",
       " 1975,\n",
       " 134,\n",
       " 3225,\n",
       " 581,\n",
       " 926,\n",
       " 1030,\n",
       " 553,\n",
       " 2229,\n",
       " 524,\n",
       " 3248,\n",
       " 3565,\n",
       " 1015,\n",
       " 1478,\n",
       " 2581,\n",
       " 2359,\n",
       " 1430,\n",
       " 797,\n",
       " 1720,\n",
       " 3422,\n",
       " 3540,\n",
       " 1234,\n",
       " 128,\n",
       " 2868,\n",
       " 2517,\n",
       " 1847,\n",
       " 2823,\n",
       " 1216,\n",
       " 311,\n",
       " 1416,\n",
       " 2626,\n",
       " 1099,\n",
       " 283,\n",
       " 3306,\n",
       " 3345,\n",
       " 1229,\n",
       " 320,\n",
       " 357,\n",
       " 3331,\n",
       " 2476,\n",
       " 1870,\n",
       " 1855,\n",
       " 1580,\n",
       " 2381,\n",
       " 1921,\n",
       " 2014,\n",
       " 3421,\n",
       " ...]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_object.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0ef177c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[476,\n",
       " 476,\n",
       " 476,\n",
       " 476,\n",
       " 476,\n",
       " 4385,\n",
       " 4385,\n",
       " 4385,\n",
       " 4385,\n",
       " 4385,\n",
       " 2236,\n",
       " 2236,\n",
       " 2236,\n",
       " 2236,\n",
       " 2236,\n",
       " 498,\n",
       " 498,\n",
       " 498,\n",
       " 498,\n",
       " 498,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 5004,\n",
       " 5004,\n",
       " 5004,\n",
       " 5004,\n",
       " 5004,\n",
       " 3944,\n",
       " 3944,\n",
       " 3944,\n",
       " 3944,\n",
       " 3944,\n",
       " 4415,\n",
       " 4415,\n",
       " 4415,\n",
       " 4415,\n",
       " 4415,\n",
       " 779,\n",
       " 779,\n",
       " 779,\n",
       " 779,\n",
       " 779,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 5636,\n",
       " 5636,\n",
       " 5636,\n",
       " 5636,\n",
       " 5636,\n",
       " 1214,\n",
       " 1214,\n",
       " 1214,\n",
       " 1214,\n",
       " 1214,\n",
       " 493,\n",
       " 493,\n",
       " 493,\n",
       " 493,\n",
       " 493,\n",
       " 4636,\n",
       " 4636,\n",
       " 4636,\n",
       " 4636,\n",
       " 4636,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 391,\n",
       " 2856,\n",
       " 2856,\n",
       " 2856,\n",
       " 2856,\n",
       " 2856,\n",
       " 523,\n",
       " 523,\n",
       " 523,\n",
       " 523,\n",
       " 523,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 4939,\n",
       " 4939,\n",
       " 4939,\n",
       " 4939,\n",
       " 4939,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 3468,\n",
       " 3468,\n",
       " 3468,\n",
       " 3468,\n",
       " 3468,\n",
       " 1570,\n",
       " 1570,\n",
       " 1570,\n",
       " 1570,\n",
       " 1570,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 2540,\n",
       " 2540,\n",
       " 2540,\n",
       " 2540,\n",
       " 2540,\n",
       " 4374,\n",
       " 4374,\n",
       " 4374,\n",
       " 4374,\n",
       " 4374,\n",
       " 3653,\n",
       " 3653,\n",
       " 3653,\n",
       " 3653,\n",
       " 3653,\n",
       " 4713,\n",
       " 4713,\n",
       " 4713,\n",
       " 4713,\n",
       " 4713,\n",
       " 5647,\n",
       " 5647,\n",
       " 5647,\n",
       " 5647,\n",
       " 5647,\n",
       " 4088,\n",
       " 4088,\n",
       " 4088,\n",
       " 4088,\n",
       " 4088,\n",
       " 3028,\n",
       " 3028,\n",
       " 3028,\n",
       " 3028,\n",
       " 3028,\n",
       " 1761,\n",
       " 1761,\n",
       " 1761,\n",
       " 1761,\n",
       " 1761,\n",
       " 923,\n",
       " 923,\n",
       " 923,\n",
       " 923,\n",
       " 923,\n",
       " 5457,\n",
       " 5457,\n",
       " 5457,\n",
       " 5457,\n",
       " 5457,\n",
       " 5796,\n",
       " 5796,\n",
       " 5796,\n",
       " 5796,\n",
       " 5796,\n",
       " 849,\n",
       " 849,\n",
       " 849,\n",
       " 849,\n",
       " 849,\n",
       " 4832,\n",
       " 4832,\n",
       " 4832,\n",
       " 4832,\n",
       " 4832,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 945,\n",
       " 821,\n",
       " 821,\n",
       " 821,\n",
       " 821,\n",
       " 821,\n",
       " 3190,\n",
       " 3190,\n",
       " 3190,\n",
       " 3190,\n",
       " 3190,\n",
       " 659,\n",
       " 659,\n",
       " 659,\n",
       " 659,\n",
       " 659,\n",
       " 4463,\n",
       " 4463,\n",
       " 4463,\n",
       " 4463,\n",
       " 4463,\n",
       " 1218,\n",
       " 1218,\n",
       " 1218,\n",
       " 1218,\n",
       " 1218,\n",
       " 807,\n",
       " 807,\n",
       " 807,\n",
       " 807,\n",
       " 807,\n",
       " 3463,\n",
       " 3463,\n",
       " 3463,\n",
       " 3463,\n",
       " 3463,\n",
       " 1529,\n",
       " 1529,\n",
       " 1529,\n",
       " 1529,\n",
       " 1529,\n",
       " 4237,\n",
       " 4237,\n",
       " 4237,\n",
       " 4237,\n",
       " 4237,\n",
       " 1028,\n",
       " 1028,\n",
       " 1028,\n",
       " 1028,\n",
       " 1028,\n",
       " 5171,\n",
       " 5171,\n",
       " 5171,\n",
       " 5171,\n",
       " 5171,\n",
       " 3273,\n",
       " 3273,\n",
       " 3273,\n",
       " 3273,\n",
       " 3273,\n",
       " 1411,\n",
       " 1411,\n",
       " 1411,\n",
       " 1411,\n",
       " 1411,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 3023,\n",
       " 3023,\n",
       " 3023,\n",
       " 3023,\n",
       " 3023,\n",
       " 4945,\n",
       " 4945,\n",
       " 4945,\n",
       " 4945,\n",
       " 4945,\n",
       " 3767,\n",
       " 3767,\n",
       " 3767,\n",
       " 3767,\n",
       " 3767,\n",
       " 2053,\n",
       " 2053,\n",
       " 2053,\n",
       " 2053,\n",
       " 2053,\n",
       " 1332,\n",
       " 1332,\n",
       " 1332,\n",
       " 1332,\n",
       " 1332,\n",
       " 2392,\n",
       " 2392,\n",
       " 2392,\n",
       " 2392,\n",
       " 2392,\n",
       " 1464,\n",
       " 1464,\n",
       " 1464,\n",
       " 1464,\n",
       " 1464,\n",
       " 5034,\n",
       " 5034,\n",
       " 5034,\n",
       " 5034,\n",
       " 5034,\n",
       " 5373,\n",
       " 5373,\n",
       " 5373,\n",
       " 5373,\n",
       " 5373,\n",
       " 302,\n",
       " 302,\n",
       " 302,\n",
       " 302,\n",
       " 302,\n",
       " 2260,\n",
       " 2260,\n",
       " 2260,\n",
       " 2260,\n",
       " 2260,\n",
       " 5956,\n",
       " 5956,\n",
       " 5956,\n",
       " 5956,\n",
       " 5956,\n",
       " 4844,\n",
       " 4844,\n",
       " 4844,\n",
       " 4844,\n",
       " 4844,\n",
       " 5183,\n",
       " 5183,\n",
       " 5183,\n",
       " 5183,\n",
       " 5183,\n",
       " 5219,\n",
       " 5219,\n",
       " 5219,\n",
       " 5219,\n",
       " 5219,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 260,\n",
       " 1968,\n",
       " 1968,\n",
       " 1968,\n",
       " 1968,\n",
       " 1968,\n",
       " 3315,\n",
       " 3315,\n",
       " 3315,\n",
       " 3315,\n",
       " 3315,\n",
       " 1004,\n",
       " 1004,\n",
       " 1004,\n",
       " 1004,\n",
       " 1004,\n",
       " 5023,\n",
       " 5023,\n",
       " 5023,\n",
       " 5023,\n",
       " 5023,\n",
       " 2123,\n",
       " 2123,\n",
       " 2123,\n",
       " 2123,\n",
       " 2123,\n",
       " 2410,\n",
       " 2410,\n",
       " 2410,\n",
       " 2410,\n",
       " 2410,\n",
       " 1321,\n",
       " 1321,\n",
       " 1321,\n",
       " 1321,\n",
       " 1321,\n",
       " 3470,\n",
       " 3470,\n",
       " 3470,\n",
       " 3470,\n",
       " 3470,\n",
       " 2506,\n",
       " 2506,\n",
       " 2506,\n",
       " 2506,\n",
       " 2506,\n",
       " 2933,\n",
       " 2933,\n",
       " 2933,\n",
       " 2933,\n",
       " 2933,\n",
       " 2308,\n",
       " 2308,\n",
       " 2308,\n",
       " 2308,\n",
       " 2308,\n",
       " 5326,\n",
       " 5326,\n",
       " 5326,\n",
       " 5326,\n",
       " 5326,\n",
       " 5613,\n",
       " 5613,\n",
       " 5613,\n",
       " 5613,\n",
       " 5613,\n",
       " 594,\n",
       " 594,\n",
       " 594,\n",
       " 594,\n",
       " 594,\n",
       " 2891,\n",
       " 2891,\n",
       " 2891,\n",
       " 2891,\n",
       " 2891,\n",
       " 5076,\n",
       " 5076,\n",
       " 5076,\n",
       " 5076,\n",
       " 5076,\n",
       " 1815,\n",
       " 1815,\n",
       " 1815,\n",
       " 1815,\n",
       " 1815,\n",
       " 4886,\n",
       " 4886,\n",
       " 4886,\n",
       " 4886,\n",
       " 4886,\n",
       " 1338,\n",
       " 1338,\n",
       " 1338,\n",
       " 1338,\n",
       " 1338,\n",
       " 1625,\n",
       " 1625,\n",
       " 1625,\n",
       " 1625,\n",
       " 1625,\n",
       " 5856,\n",
       " 5856,\n",
       " 5856,\n",
       " 5856,\n",
       " 5856,\n",
       " 4194,\n",
       " 4194,\n",
       " 4194,\n",
       " 4194,\n",
       " 4194,\n",
       " 713,\n",
       " 713,\n",
       " 713,\n",
       " 713,\n",
       " 713,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 4054,\n",
       " 4054,\n",
       " 4054,\n",
       " 4054,\n",
       " 4054,\n",
       " 2994,\n",
       " 2994,\n",
       " 2994,\n",
       " 2994,\n",
       " 2994,\n",
       " 3421,\n",
       " 3421,\n",
       " 3421,\n",
       " 3421,\n",
       " 3421,\n",
       " 5754,\n",
       " 5754,\n",
       " 5754,\n",
       " 5754,\n",
       " 5754,\n",
       " 3142,\n",
       " 3142,\n",
       " 3142,\n",
       " 3142,\n",
       " 3142,\n",
       " 3517,\n",
       " 3517,\n",
       " 3517,\n",
       " 3517,\n",
       " 3517,\n",
       " 2796,\n",
       " 2796,\n",
       " 2796,\n",
       " 2796,\n",
       " 2796,\n",
       " 4040,\n",
       " 4040,\n",
       " 4040,\n",
       " 4040,\n",
       " 4040,\n",
       " 2928,\n",
       " 2928,\n",
       " 2928,\n",
       " 2928,\n",
       " 2928,\n",
       " 5077,\n",
       " 5077,\n",
       " 5077,\n",
       " 5077,\n",
       " 5077,\n",
       " 3112,\n",
       " 3112,\n",
       " 3112,\n",
       " 3112,\n",
       " 3112,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 6035,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 4724,\n",
       " 2303,\n",
       " 2303,\n",
       " 2303,\n",
       " 2303,\n",
       " 2303,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 5999,\n",
       " 3225,\n",
       " 3225,\n",
       " 3225,\n",
       " 3225,\n",
       " 3225,\n",
       " 4446,\n",
       " 4446,\n",
       " 4446,\n",
       " 4446,\n",
       " 4446,\n",
       " 1201,\n",
       " 1201,\n",
       " 1201,\n",
       " 1201,\n",
       " 1201,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 3107,\n",
       " 4542,\n",
       " 4542,\n",
       " 4542,\n",
       " 4542,\n",
       " 4542,\n",
       " 1297,\n",
       " 1297,\n",
       " 1297,\n",
       " 1297,\n",
       " 1297,\n",
       " 2857,\n",
       " 2857,\n",
       " 2857,\n",
       " 2857,\n",
       " 2857,\n",
       " 5529,\n",
       " 5529,\n",
       " 5529,\n",
       " 5529,\n",
       " 5529,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 3939,\n",
       " 3851,\n",
       " 3851,\n",
       " 3851,\n",
       " 3851,\n",
       " 3851,\n",
       " 570,\n",
       " 570,\n",
       " 570,\n",
       " 570,\n",
       " 570,\n",
       " 179,\n",
       " 179,\n",
       " 179,\n",
       " 179,\n",
       " 179,\n",
       " 1254,\n",
       " 1254,\n",
       " 1254,\n",
       " 1254,\n",
       " 1254,\n",
       " 1202,\n",
       " 1202,\n",
       " 1202,\n",
       " 1202,\n",
       " 1202,\n",
       " 4309,\n",
       " 4309,\n",
       " 4309,\n",
       " 4309,\n",
       " 4309,\n",
       " 5892,\n",
       " 5892,\n",
       " 5892,\n",
       " 5892,\n",
       " 5892,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 2683,\n",
       " 2683,\n",
       " 2683,\n",
       " 2683,\n",
       " 2683,\n",
       " 1284,\n",
       " 1284,\n",
       " 1284,\n",
       " 1284,\n",
       " 1284,\n",
       " 2292,\n",
       " 2292,\n",
       " 2292,\n",
       " 2292,\n",
       " 2292,\n",
       " 4405,\n",
       " 4405,\n",
       " 4405,\n",
       " 4405,\n",
       " 4405,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 4868,\n",
       " 623,\n",
       " 623,\n",
       " 623,\n",
       " 623,\n",
       " 623,\n",
       " 607,\n",
       " 607,\n",
       " 607,\n",
       " 607,\n",
       " 607,\n",
       " 1058,\n",
       " 1058,\n",
       " 1058,\n",
       " 1058,\n",
       " 1058,\n",
       " 880,\n",
       " 880,\n",
       " 880,\n",
       " 880,\n",
       " 880,\n",
       " 4185,\n",
       " 4185,\n",
       " 4185,\n",
       " 4185,\n",
       " 4185,\n",
       " 3053,\n",
       " 3053,\n",
       " 3053,\n",
       " 3053,\n",
       " 3053,\n",
       " 1654,\n",
       " 1654,\n",
       " 1654,\n",
       " 1654,\n",
       " 1654,\n",
       " 565,\n",
       " 565,\n",
       " 565,\n",
       " 565,\n",
       " 565,\n",
       " 852,\n",
       " 852,\n",
       " 852,\n",
       " 852,\n",
       " 852,\n",
       " 2750,\n",
       " 2750,\n",
       " 2750,\n",
       " 2750,\n",
       " 2750,\n",
       " 2177,\n",
       " 2177,\n",
       " 2177,\n",
       " 2177,\n",
       " 2177,\n",
       " 4023,\n",
       " 4023,\n",
       " 4023,\n",
       " 4023,\n",
       " 4023,\n",
       " 5386,\n",
       " 5386,\n",
       " 5386,\n",
       " 5386,\n",
       " 5386,\n",
       " 874,\n",
       " 874,\n",
       " 874,\n",
       " 874,\n",
       " 874,\n",
       " 1588,\n",
       " 1588,\n",
       " 1588,\n",
       " 1588,\n",
       " 1588,\n",
       " 1023,\n",
       " 1023,\n",
       " 1023,\n",
       " 1023,\n",
       " 1023,\n",
       " 1059,\n",
       " 1059,\n",
       " 1059,\n",
       " 1059,\n",
       " 1059,\n",
       " 1095,\n",
       " 1095,\n",
       " 1095,\n",
       " 1095,\n",
       " 1095,\n",
       " 1957,\n",
       " 1957,\n",
       " 1957,\n",
       " 1957,\n",
       " 1957,\n",
       " 3915,\n",
       " 3915,\n",
       " 3915,\n",
       " 3915,\n",
       " 3915,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 470,\n",
       " 470,\n",
       " 470,\n",
       " 470,\n",
       " 470,\n",
       " 4386,\n",
       " 4386,\n",
       " 4386,\n",
       " 4386,\n",
       " 4386,\n",
       " 191,\n",
       " 191,\n",
       " 191,\n",
       " 191,\n",
       " 191,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 530,\n",
       " 957,\n",
       " 957,\n",
       " 957,\n",
       " 957,\n",
       " 957,\n",
       " 3761,\n",
       " 3761,\n",
       " 3761,\n",
       " 3761,\n",
       " 3761,\n",
       " 5483,\n",
       " 5483,\n",
       " 5483,\n",
       " 5483,\n",
       " 5483,\n",
       " 3850,\n",
       " 3850,\n",
       " 3850,\n",
       " 3850,\n",
       " 3850,\n",
       " 2673,\n",
       " 2673,\n",
       " 2673,\n",
       " 2673,\n",
       " 2673,\n",
       " 3100,\n",
       " 3100,\n",
       " 3100,\n",
       " 3100,\n",
       " 3100,\n",
       " 1649,\n",
       " 1649,\n",
       " 1649,\n",
       " 1649,\n",
       " 1649,\n",
       " 3946,\n",
       " 3946,\n",
       " 3946,\n",
       " 3946,\n",
       " 3946,\n",
       " 2886,\n",
       " 2886,\n",
       " 2886,\n",
       " 2886,\n",
       " 2886,\n",
       " 4373,\n",
       " 4373,\n",
       " 4373,\n",
       " 4373,\n",
       " 4373,\n",
       " 4756,\n",
       " 4756,\n",
       " 4756,\n",
       " 4756,\n",
       " 4756,\n",
       " 1172,\n",
       " 1172,\n",
       " 1172,\n",
       " 1172,\n",
       " 1172,\n",
       " 5802,\n",
       " 5802,\n",
       " 5802,\n",
       " 5802,\n",
       " 5802,\n",
       " 5411,\n",
       " 5411,\n",
       " 5411,\n",
       " 5411,\n",
       " 5411,\n",
       " 1643,\n",
       " 1643,\n",
       " 1643,\n",
       " 1643,\n",
       " 1643,\n",
       " 244,\n",
       " 244,\n",
       " 244,\n",
       " 244,\n",
       " 244,\n",
       " 1018,\n",
       " 1018,\n",
       " 1018,\n",
       " 1018,\n",
       " 1018,\n",
       " 3690,\n",
       " 3690,\n",
       " 3690,\n",
       " 3690,\n",
       " 3690,\n",
       " 2239,\n",
       " 2239,\n",
       " 2239,\n",
       " 2239,\n",
       " 2239,\n",
       " 481,\n",
       " 481,\n",
       " 481,\n",
       " 481,\n",
       " 481,\n",
       " 3065,\n",
       " 3065,\n",
       " 3065,\n",
       " 3065,\n",
       " 3065,\n",
       " 1666,\n",
       " 1666,\n",
       " 1666,\n",
       " 1666,\n",
       " 1666,\n",
       " 423,\n",
       " 423,\n",
       " 423,\n",
       " 423,\n",
       " 423,\n",
       " 762,\n",
       " 762,\n",
       " 762,\n",
       " 762,\n",
       " 762,\n",
       " 3398,\n",
       " 3398,\n",
       " 3398,\n",
       " 3398,\n",
       " 3398,\n",
       " 3506,\n",
       " 3506,\n",
       " 3506,\n",
       " 3506,\n",
       " 3506,\n",
       " 1446,\n",
       " 1446,\n",
       " 1446,\n",
       " 1446,\n",
       " 1446,\n",
       " 1167,\n",
       " 1167,\n",
       " 1167,\n",
       " 1167,\n",
       " 1167,\n",
       " 1845,\n",
       " 1845,\n",
       " 1845,\n",
       " 1845,\n",
       " 1845,\n",
       " 2743,\n",
       " 2743,\n",
       " 2743,\n",
       " 2743,\n",
       " 2743,\n",
       " 4178,\n",
       " 4178,\n",
       " 4178,\n",
       " 4178,\n",
       " 4178,\n",
       " 2280,\n",
       " 2280,\n",
       " 2280,\n",
       " 2280,\n",
       " 2280,\n",
       " 3589,\n",
       " 3589,\n",
       " 3589,\n",
       " 3589,\n",
       " 3589,\n",
       " 344,\n",
       " 344,\n",
       " 344,\n",
       " 344,\n",
       " 344,\n",
       " 440,\n",
       " 440,\n",
       " 440,\n",
       " 440,\n",
       " 440,\n",
       " 5393,\n",
       " 5393,\n",
       " 5393,\n",
       " 5393,\n",
       " 5393,\n",
       " 3886,\n",
       " 3886,\n",
       " 3886,\n",
       " 3886,\n",
       " 3886,\n",
       " 2148,\n",
       " 2148,\n",
       " 2148,\n",
       " 2148,\n",
       " 2148,\n",
       " 4672,\n",
       " 4672,\n",
       " 4672,\n",
       " 4672,\n",
       " 4672,\n",
       " 589,\n",
       " 589,\n",
       " 589,\n",
       " 589,\n",
       " 589,\n",
       " 697,\n",
       " 697,\n",
       " 697,\n",
       " 697,\n",
       " 697,\n",
       " ...]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_object.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e6a96f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_object.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "aee21fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994169"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_train_object.user_item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8348ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155338.90625"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "994169*5 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "517f55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c33834bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFTestDataset(Dataset):\n",
    "    def __init__(self, test_csv, test_negative_csv):\n",
    "        \n",
    "        self.test_ratings = pd.read_csv(test_csv)\n",
    "        self.test_negatives = pd.read_csv(test_negative_csv)\n",
    "        \n",
    "        assert len(self.test_ratings) == len(self.test_negatives)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.test_ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user = self.test_ratings.iloc[idx, 0]\n",
    "        item = self.test_ratings.iloc[idx, 1]\n",
    "        negatives = list(map(int, self.test_negatives.iloc[idx, 2].strip(\"[]\").split(\",\")) )\n",
    "        # print(negatives)\n",
    "        return torch.tensor(user, dtype=torch.long), torch.tensor(item, dtype=torch.long), torch.tensor(negatives, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3bd97901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NCFTestDataset at 0x1441caa2f60>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_object = NCFTestDataset(r\"NCF_Pytorch\\test_data.csv\",r\"NCF_Pytorch\\test_negative_data.csv\")\n",
    "\n",
    "test_test_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "71bf8521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[2216, 209, 2347, 3, 1652, 3397, 383, 2905, 2284, 2866, 584, 783, 3208, 1534, 2529, 1907, 1170, 3037, 2015, 1045, 3099, 3298, 2522, 739, 2652, 3702, 792, 2527, 1945, 2333, 1668, 3511, 70, 1991, 3071, 2474, 1629, 3221, 505, 3266, 1475, 515, 2704, 1717, 569, 3248, 241, 2643, 2137, 2336, 2627, 2618, 2748, 2967, 2579, 1732, 3283, 1440, 1052, 1906, 1812, 1182, 2831, 1548, 1630, 2227, 2352, 760, 350, 302, 791, 300, 3528, 1444, 2, 798, 997, 376, 2565, 1565, 718, 710, 2695, 904, 3643, 655, 3666, 3069, 3661, 953, 865, 813, 1353, 2945, 2580, 2989, 2790, 2879, 2481]'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_object.test_negatives.iloc[2,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "abbe2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID               2\n",
       "ItemID             207\n",
       "Rating               4\n",
       "Timestamp    978298504\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_object.test_ratings.iloc[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "18a1a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1441caa3440>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_object_loader = DataLoader(test_test_object, 32, shuffle=True)\n",
    "test_train_object_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9dc1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "61b6fd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_train_object_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "885eebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users shape:  tensor([6022, 1862, 4126, 2721, 2180, 2298, 3210, 2572, 4184, 5598,  506, 1361,\n",
      "        1431, 5248, 2645, 5769, 3598, 1673, 5618, 4200, 3567, 3092,  689, 3950,\n",
      "          67, 4952, 2897, 5884, 3012,  434, 4747,  889])\n",
      "Iterms shape:  tensor([1224, 1497,  606,   44,  386,  934,  999,  792, 2556, 1055,  377, 1624,\n",
      "         743,  891, 1405, 1998, 1653,  269, 1066,  541,  847, 1503,  532,  934,\n",
      "          19, 1838,  350,  246,  408,  733, 1643,  760])\n",
      "labels shape:  tensor([[ 864,  582, 1426,  ..., 1484, 1770,  463],\n",
      "        [2823,  290, 2994,  ..., 2907, 3621, 2228],\n",
      "        [2151,  381, 2127,  ...,   39, 1034, 2586],\n",
      "        ...,\n",
      "        [2628, 3015,  910,  ..., 2142, 1744,  749],\n",
      "        [ 875,  878, 1465,  ..., 2236,  258, 2845],\n",
      "        [2155, 1871,  541,  ..., 3097, 3296, 1306]])\n",
      "Users shape:  torch.Size([32])\n",
      "Iterms shape:  torch.Size([32])\n",
      "labels shape:  torch.Size([32, 99])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_train_object_loader:\n",
    "    user, item, labels = batch \n",
    "    print(\"Users shape: \", user)\n",
    "    print(\"Iterms shape: \", item)\n",
    "    print(\"labels shape: \", labels)\n",
    "    \n",
    "    print(\"Users shape: \", user.shape)\n",
    "    print(\"Iterms shape: \", item.shape)\n",
    "    print(\"labels shape: \", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c94f4b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6035</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>956755196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6036</td>\n",
       "      <td>294</td>\n",
       "      <td>4</td>\n",
       "      <td>956801840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6037</td>\n",
       "      <td>1528</td>\n",
       "      <td>5</td>\n",
       "      <td>956717204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6038</td>\n",
       "      <td>1449</td>\n",
       "      <td>5</td>\n",
       "      <td>956758029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6039</td>\n",
       "      <td>434</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  ItemID  Rating  Timestamp\n",
       "0          0      25       5  978824351\n",
       "1          1     133       3  978300174\n",
       "2          2     207       4  978298504\n",
       "3          3     208       4  978294282\n",
       "4          4     222       2  978246585\n",
       "...      ...     ...     ...        ...\n",
       "6035    6035    1048       1  956755196\n",
       "6036    6036     294       4  956801840\n",
       "6037    6037    1528       5  956717204\n",
       "6038    6038    1449       5  956758029\n",
       "6039    6039     434       4  998315055\n",
       "\n",
       "[6040 rows x 4 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_object.test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce8204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UserID</td>\n",
       "      <td>ItemID</td>\n",
       "      <td>NegativeItems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>[1064, 174, 2791, 3373, 269, 2678, 1902, 3641,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>[1072, 3154, 3368, 3644, 549, 1810, 937, 1514,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>[2216, 209, 2347, 3, 1652, 3397, 383, 2905, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>[3023, 1489, 1916, 1706, 1221, 1191, 2671, 81,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6035</td>\n",
       "      <td>1048</td>\n",
       "      <td>[2495, 3406, 819, 729, 1920, 2003, 3329, 2351,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6036</td>\n",
       "      <td>294</td>\n",
       "      <td>[2248, 1318, 3661, 72, 351, 2131, 3281, 2482, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6037</td>\n",
       "      <td>1528</td>\n",
       "      <td>[2194, 867, 1424, 2517, 3080, 2789, 1210, 3150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6038</td>\n",
       "      <td>1449</td>\n",
       "      <td>[2606, 2054, 2754, 1299, 2854, 2413, 1055, 742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6039</td>\n",
       "      <td>434</td>\n",
       "      <td>[3289, 3432, 2599, 2162, 1653, 2363, 2576, 131...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6041 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1                                                  2\n",
       "0     UserID  ItemID                                      NegativeItems\n",
       "1          0      25  [1064, 174, 2791, 3373, 269, 2678, 1902, 3641,...\n",
       "2          1     133  [1072, 3154, 3368, 3644, 549, 1810, 937, 1514,...\n",
       "3          2     207  [2216, 209, 2347, 3, 1652, 3397, 383, 2905, 22...\n",
       "4          3     208  [3023, 1489, 1916, 1706, 1221, 1191, 2671, 81,...\n",
       "...      ...     ...                                                ...\n",
       "6036    6035    1048  [2495, 3406, 819, 729, 1920, 2003, 3329, 2351,...\n",
       "6037    6036     294  [2248, 1318, 3661, 72, 351, 2131, 3281, 2482, ...\n",
       "6038    6037    1528  [2194, 867, 1424, 2517, 3080, 2789, 1210, 3150...\n",
       "6039    6038    1449  [2606, 2054, 2754, 1299, 2854, 2413, 1055, 742...\n",
       "6040    6039     434  [3289, 3432, 2599, 2162, 1653, 2363, 2576, 131...\n",
       "\n",
       "[6041 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_object.test_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a281b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6266f8e1",
   "metadata": {},
   "source": [
    "## let's first make the evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacbeda",
   "metadata": {},
   "source": [
    "# HR@K (Hit Ratio @ K)\n",
    "\n",
    "    - Measures whether the ground-truth item is in the top-K predicted list.\n",
    "    - For each user, if the true item is in the top-K list, HR = 1, else 0.\n",
    "    - Then average across all users.\n",
    "    - Intuition: “Did we recommend the right movie in the top 10?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fc594",
   "metadata": {},
   "source": [
    "# NDCG@K (Normalized Discounted Cumulative Gain)\n",
    "\n",
    "    - Similar to HR@K, but also considers ranking position of the true item.\n",
    "    - The earlier the true item appears in the list, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff414bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d98c7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFEvaluator:\n",
    "    def __init__(self, model, test_negative_dataset, top_k=10, device='cpu'):\n",
    "        self.model = model\n",
    "        self.test_dataset = test_negative_dataset\n",
    "        self.top_k = top_k\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate(self):\n",
    "        ndcg = []\n",
    "        hit = []\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx in range(len(self.test_dataset)):\n",
    "                \n",
    "                user, pos_item, neg_items = self.test_dataset[idx]\n",
    "                # print(user)\n",
    "                # print(pos_item)\n",
    "                # print(neg_items)\n",
    "                \n",
    "                \n",
    "                # print(user.dtype)\n",
    "                # print(pos_item.dtype)\n",
    "                # print(neg_items.dtype)\n",
    "                \n",
    "                users = user.repeat(len(neg_items) + 1).to(self.device)\n",
    "                items = torch.cat((torch.tensor([pos_item]), neg_items), dim=0).to(self.device)\n",
    "                \n",
    "                ## get prediction scores\n",
    "                scores = self.model(users, items).cpu().numpy()\n",
    "                \n",
    "                ## Top k rank\n",
    "                map_item_score = {item : score for item, score in zip(items.tolist(), scores.tolist())}\n",
    "                \n",
    "                ranklist= heapq.nlargest(self.top_k, map_item_score, key= map_item_score.get)\n",
    "                \n",
    "                # Metrics\n",
    "                hr_val = self.getHitRate(ranklist, pos_item)\n",
    "                ndcg_val = self.getNDCG(ranklist, pos_item)\n",
    "                \n",
    "                hit.append(hr_val)\n",
    "                ndcg.append(ndcg_val)\n",
    "                \n",
    "        return (hit, ndcg)\n",
    "    \n",
    "    def getHitRate(self, ranklist, get_item):\n",
    "        for item in ranklist:\n",
    "            if item == get_item:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    def getNDCG(self, ranklist, get_item):\n",
    "        for i, item in enumerate(ranklist):\n",
    "            \n",
    "            if item == get_item:\n",
    "                return math.log(2) / math.log(i+2)\n",
    "            \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc097c14",
   "metadata": {},
   "source": [
    "# Define some Common Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2c64a97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhruv\\\\Documents\\\\DA-IICT\\\\Arpit_rana\\\\MajorProject'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "538d1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "train_data : NCF_Pytorch\\train_data.csv\n",
      "test_data : NCF_Pytorch\\test_data.csv\n",
      "test_negative_data : NCF_Pytorch\\test_negative_data.csv\n",
      "dataset : ml-1m\n",
      "regs : [0, 0]\n",
      "lr : 0.001\n",
      "batch_size : 256\n",
      "epochs : 10\n",
      "learner : adam\n",
      "num_factors : 10\n",
      "num_layers : 3\n",
      "num_neg : 2\n",
      "verbose : 2\n",
      "out : True\n"
     ]
    }
   ],
   "source": [
    "topK = 10\n",
    "\n",
    "configurations = {\n",
    "    \"train_data\" : r\"NCF_Pytorch\\train_data.csv\",\n",
    "    \"test_data\" : r\"NCF_Pytorch\\test_data.csv\",\n",
    "    \"test_negative_data\" : r\"NCF_Pytorch\\test_negative_data.csv\",\n",
    "    \n",
    "    'dataset': 'ml-1m',\n",
    "    'regs': [0, 0],\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'epochs': 10,          ## Training Epochs\n",
    "    'learner': 'adam',\n",
    "    'num_factors': 10,\n",
    "    'num_layers': 3,\n",
    "    'num_neg': 2,\n",
    "    'verbose': 2,\n",
    "    'out': True,\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f58adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b26313e",
   "metadata": {},
   "source": [
    "# Start GMF Model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "8a31cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2aada18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets first find out the uniques no of users and items in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "602be8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = max(test_train_object.train_df.UserID) + 1\n",
    "num_items = max(test_train_object.train_df.ItemID) + 1\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ba63271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, reg):\n",
    "        super(GMF, self).__init__()\n",
    "        \n",
    "        ## Users and items embeddings\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_embeddings=num_users, embedding_dim=latent_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_embeddings=num_items, embedding_dim=latent_dim)\n",
    "        \n",
    "        self.output = nn.Linear(latent_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        ### set the initializer \n",
    "        nn.init.normal_(self.user_embeddings.weight, mean=0, std = 0.01)\n",
    "        nn.init.normal_(self.item_embeddings.weight, mean=0, std = 0.01)\n",
    "        \n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        user_latent = self.user_embeddings(user)\n",
    "        item_latent = self.item_embeddings(item)\n",
    "        \n",
    "        interaction = user_latent * item_latent\n",
    "        \n",
    "        out = self.output(interaction)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "50841b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMF(\n",
       "  (user_embeddings): Embedding(6040, 10)\n",
       "  (item_embeddings): Embedding(3706, 10)\n",
       "  (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GMF(num_users= num_users, num_items=num_items, latent_dim=configurations[\"num_factors\"],reg=[0,0])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "5f13f42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0057, -0.0058, -0.0050,  0.0224, -0.0051, -0.0165,  0.0023,  0.0073,\n",
       "        -0.0050,  0.0054], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_embeddings(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "efac736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.7208e-05, -3.7751e-03, -9.9150e-03, -1.2664e-02, -1.7703e-02,\n",
       "        -3.1086e-04,  8.8837e-03, -6.0281e-03, -2.8893e-04,  1.1641e-02],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_embeddings(torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0405ae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_embeddings(torch.tensor([1,2,3,4])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "8218b83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCF_Pytorch\\\\test_negative_data.csv'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations[\"test_negative_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "4c913ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NCFTestDataset at 0x1441c656cc0>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dataset =  NCFTestDataset(configurations[\"test_data\"], configurations[\"test_negative_data\"])\n",
    "demo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "bd4d0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NCFEvaluator at 0x1441c657a70>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = NCFEvaluator(model, demo_dataset)\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "efa32a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrate_value, ndcg_value = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "add204b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09437086092715231, 0.042547239653144886)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hrate_value)/len(hrate_value), sum(ndcg_value)/len(ndcg_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b37e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093078e3",
   "metadata": {},
   "source": [
    "# GMF Traning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0636f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7459a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhruv\\\\Documents\\\\DA-IICT\\\\Arpit_rana\\\\MajorProject\\\\NCF_Pytorch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a28047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_1m_dataset import NCFTestDataset, NCFTrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564e234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NCF_evaluation import NCFEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca520a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "train_data : train_data.csv\n",
      "test_data : test_data.csv\n",
      "test_negative_data : test_negative_data.csv\n",
      "dataset : ml-1m\n",
      "regs : [0, 0]\n",
      "lr : 0.001\n",
      "batch_size : 256\n",
      "epochs : 3\n",
      "learner : adam\n",
      "num_factors : 10\n",
      "num_layers : 3\n",
      "num_neg : 2\n",
      "out : True\n"
     ]
    }
   ],
   "source": [
    "topK = 10\n",
    "\n",
    "configurations = {\n",
    "    \"train_data\" : r\"train_data.csv\",\n",
    "    \"test_data\" : r\"test_data.csv\",\n",
    "    \"test_negative_data\" : r\"test_negative_data.csv\",\n",
    "    \n",
    "    'dataset': 'ml-1m',\n",
    "    'regs': [0, 0],\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'epochs': 3,          ## Training Epochs\n",
    "    'learner': 'adam',\n",
    "    'num_factors': 10,\n",
    "    'num_layers': 3,\n",
    "    'num_neg': 2,\n",
    "    'out': True,\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d266779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ml_1m_dataset.NCFTrainDataset at 0x27749b560c0>,\n",
       " <ml_1m_dataset.NCFTestDataset at 0x2775f41f200>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data path :\n",
    "train_data_path = \"train_data.csv\"\n",
    "test_data_path = \"test_data.csv\"\n",
    "test_negative_data_path = \"test_negative_data.csv\"\n",
    "\n",
    "train_data_object = NCFTrainDataset(train_csv=train_data_path, num_negatives=configurations[\"num_neg\"])\n",
    "\n",
    "test_data_object = NCFTestDataset(test_csv=test_data_path, test_negative_csv=test_negative_data_path)\n",
    "\n",
    "train_data_object, test_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf3d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e94641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_negative_dataset, config, NCFEvaluation, device=\"cpu\"):\n",
    "    \n",
    "    if config[\"learner\"].lower() == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "        \n",
    "    elif config[\"learner\"].lower() == \"adagrad\":\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=config[\"lr\"])\n",
    "    elif config[\"learner\"].lower() == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=config[\"lr\"])\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "        \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    evaluator = NCFEvaluation(model, test_negative_dataset)\n",
    "    \n",
    "    best_hr, best_ndcg, best_epoch = 0, 0, -1\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        t1 = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        total_loss = 0 \n",
    "        \n",
    "        for users, items, labels in train_loader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(users, items)\n",
    "            \n",
    "            ## making the input and output shape and datatype same\n",
    "            \n",
    "            outputs = outputs.to(torch.float32)\n",
    "            labels = labels.to(torch.float32)\n",
    "            \n",
    "            # print(labels.shape)\n",
    "            # print(outputs.shape)\n",
    "            # print(labels.dtype)\n",
    "            # print(outputs.dtype)\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        t2 = time.time()\n",
    "        hits, ndcgs = evaluator.evaluate()\n",
    "        hits = sum(hits)/len(hits)\n",
    "        ndcgs = sum(ndcgs)/len(ndcgs)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch} [{t2-t1:.1f}s]: \\n\"\n",
    "              f\"Hit Rate: {hits:.4f}, NDCG: {ndcgs:.4f}, loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if hits > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = hits, ndcgs, epoch\n",
    "            \n",
    "            if config[\"out\"]:\n",
    "                torch.save(model.state_dict(),\n",
    "                           f\"{config[\"dataset\"]}_GMF_{config[\"num_factors\"]}.pth\")\n",
    "            print(f\"End. Best Iteration {epoch}: HR: {best_hr:.4f}, NDCG:{best_ndcg:.4f}\")\n",
    "            \n",
    "    print(f\"The Best GMF Model is Saved from epoch {best_epoch}\")\n",
    "    \n",
    "    return best_hr, best_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516029d2",
   "metadata": {},
   "source": [
    "## lets train GMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572ea917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ml_1m_dataset.NCFTrainDataset at 0x27749b560c0>,\n",
       " <ml_1m_dataset.NCFTrainDataset at 0x27749b560c0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_object, train_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c816e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_object.num_users, train_data_object.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583250f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = train_data_object.num_users\n",
    "num_items = train_data_object.num_items\n",
    "\n",
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1066f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GMF_model import GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370e3abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMF(\n",
       "  (user_embeddings): Embedding(6040, 10)\n",
       "  (item_embeddings): Embedding(3706, 10)\n",
       "  (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = GMF(num_users=num_users, num_items=num_items, latent_dim=configurations[\"num_factors\"], reg=configurations[\"regs\"])\n",
    "\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9bb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ml_1m_dataset.NCFTrainDataset at 0x27749b560c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader = DataLoader(train_data_object, configurations[\"batch_size\"], shuffle=False)\n",
    "train_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be9fc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef96704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11651"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e5641ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x27749b56090>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_loader = DataLoader(test_data_object, configurations[\"batch_size\"], shuffle=False)\n",
    "\n",
    "test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0fb8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99587d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3fb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [71.1s]: \n",
      "Hit Rate: 0.4925, NDCG: 0.2733, loss: 0.3895\n",
      "End. Best Iteration 0: HR: 0.4925, NDCG:0.2733\n",
      "Epoch 1 [71.4s]: \n",
      "Hit Rate: 0.5550, NDCG: 0.3110, loss: 0.3676\n",
      "End. Best Iteration 1: HR: 0.5550, NDCG:0.3110\n",
      "Epoch 2 [84.9s]: \n",
      "Hit Rate: 0.5786, NDCG: 0.3266, loss: 0.3501\n",
      "End. Best Iteration 2: HR: 0.5786, NDCG:0.3266\n",
      "The Best GMF Model is Saved from epoch 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5786423841059603, 0.32664566984913534)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(Model, train_loader=train_data_loader, test_dataset=test_data_object, config=configurations, NCFEvaluation=NCFEvaluator)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b24893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebae47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209f9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebde0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6f6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a5a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ee43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc1500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d3f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf-recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
