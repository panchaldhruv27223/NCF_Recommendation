{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fef8179",
   "metadata": {},
   "source": [
    "# Code By Dhruv Panchal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76ce4a",
   "metadata": {},
   "source": [
    "# train.rating:\n",
    "\n",
    "    Train file.\n",
    "    Each Line is a training instance: userID\\t itemID\\t rating\\t timestamp (if have)\n",
    "    Use case: This file is the training set. It contains all user–item interactions except the last one for each user (because last is held out for testing).\n",
    "\n",
    "\n",
    "# test.rating:\n",
    "\n",
    "    Test file (positive instances).\n",
    "    Each Line is a testing instance: userID\\t itemID\\t rating\\t timestamp (if have)\n",
    "    Use case: This is the positive ground truth for evaluation.\n",
    "    When we test, we ask: “Can the model rank this item higher than negatives for the user?”\n",
    "\n",
    "\n",
    "# test.negative\n",
    "\n",
    "    Test file (negative instances).\n",
    "    Each line corresponds to the line of test.rating, containing 99 negative samples.\n",
    "    Each line is in the format: (userID,itemID)\\t negativeItemID1\\t negativeItemID2 ...\n",
    "    \n",
    "    Interpretation (line 1):\n",
    "        User 0, ground-truth test item = 25.\n",
    "        Negatives = [1064, 174, 2791, ...] → randomly sampled items user 0 did not rate.\n",
    "\n",
    "# Big Picture\n",
    "\n",
    "    Train data = all past user interactions (except last one).\n",
    "\n",
    "    Test data = last interaction per user.\n",
    "\n",
    "    Negatives = 99 random unseen items for each user’s test.\n",
    "\n",
    "    Task = rank the true item above the negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0074cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from time import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca0b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhruv\\\\Documents\\\\DA-IICT\\\\Arpit_rana\\\\MajorProject\\\\NCF_Pytorch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b538d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dhruv\\\\Documents\\\\DA-IICT\\\\Arpit_rana\\\\MajorProject'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68699495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID  Rating  Timestamp\n",
       "0       0      32       4  978824330\n",
       "1       0      34       4  978824330\n",
       "2       0       4       5  978824291\n",
       "3       0      35       4  978824291\n",
       "4       0      30       4  978824291"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = all past user interactions (except last one).\n",
    "\n",
    "train_df = pd.read_csv(r\"previous_code\\neural_collaborative_filtering\\Data\\ml-1m.train.rating\", sep=\"\\t\", header=None, names=[\"UserID\",\"ItemID\",\"Rating\",\"Timestamp\"])\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a478506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994169"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4878f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(r\"NCF_Pytorch\\train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785b318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID  Rating  Timestamp\n",
       "0       0      25       5  978824351\n",
       "1       1     133       3  978300174\n",
       "2       2     207       4  978298504\n",
       "3       3     208       4  978294282\n",
       "4       4     222       2  978246585"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r\"previous_code\\neural_collaborative_filtering\\Data\\ml-1m.test.rating\", sep=\"\\t\", header=None, names=[\"UserID\",\"ItemID\",\"Rating\",\"Timestamp\"])\n",
    "\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6833cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(r\"NCF_Pytorch\\test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4bf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>NegativeItems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>[1064, 174, 2791, 3373, 269, 2678, 1902, 3641,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>[1072, 3154, 3368, 3644, 549, 1810, 937, 1514,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>[2216, 209, 2347, 3, 1652, 3397, 383, 2905, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>[3023, 1489, 1916, 1706, 1221, 1191, 2671, 81,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>[1794, 3535, 108, 593, 466, 2048, 854, 1378, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  ItemID                                      NegativeItems\n",
       "0       0      25  [1064, 174, 2791, 3373, 269, 2678, 1902, 3641,...\n",
       "1       1     133  [1072, 3154, 3368, 3644, 549, 1810, 937, 1514,...\n",
       "2       2     207  [2216, 209, 2347, 3, 1652, 3397, 383, 2905, 22...\n",
       "3       3     208  [3023, 1489, 1916, 1706, 1221, 1191, 2671, 81,...\n",
       "4       4     222  [1794, 3535, 108, 593, 466, 2048, 854, 1378, 1..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = []\n",
    "\n",
    "with open(r\"previous_code\\neural_collaborative_filtering\\Data\\ml-1m.test.negative\", \"r\") as file:\n",
    "    for line in file:\n",
    "        part = line.split(\"\\t\")\n",
    "        user_item = part[0].strip(\"()\").split(\",\")\n",
    "        user, pos_items = int(user_item[0]), int(user_item[1])\n",
    "        negative_items = list(map(int, part[1:]))\n",
    "        negative.append((user, pos_items, negative_items))\n",
    "        \n",
    "test_negative_df = pd.DataFrame(negative, columns=[\"UserID\", \"ItemID\", \"NegativeItems\"])\n",
    "test_negative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bcb6ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID            int64\n",
       "ItemID            int64\n",
       "NegativeItems    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negative_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfedf9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_negative_df.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a4f81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_negative_df.to_csv(r\"NCF_Pytorch\\test_negative_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee24f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42431f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9ac28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    '''\n",
    "    Dataset Class for making dataset input for the models\n",
    "    trainMatrix: training Matrix of the data\n",
    "    testRatings: positive test interactions\n",
    "    testNegatives: negative test interactions sampled for each user\n",
    "    '''\n",
    "\n",
    "    def __init__(self, path):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.trainMatrix = self.load_rating_file_as_matrix(path + \".train.rating\")\n",
    "        self.testRatings = self.load_rating_file_as_list(path + \".test.rating\")\n",
    "        self.testNegatives = self.load_negative_file(path + \".test.negative\")\n",
    "        assert len(self.testRatings) == len(self.testNegatives)\n",
    "\n",
    "        self.num_users, self.num_items = self.trainMatrix.shape\n",
    "\n",
    "    def load_rating_file_as_list(self, filename):\n",
    "        ratingList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item = int(arr[0]), int(arr[1])\n",
    "                ratingList.append([user, item])\n",
    "                line = f.readline()\n",
    "        return ratingList\n",
    "\n",
    "    def load_negative_file(self, filename):\n",
    "        negativeList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                negatives = []\n",
    "                for x in arr[1: ]:\n",
    "                    negatives.append(int(x))\n",
    "                negativeList.append(negatives)\n",
    "                line = f.readline()\n",
    "        return negativeList\n",
    "\n",
    "    def load_rating_file_as_matrix(self, filename):\n",
    "        '''\n",
    "        Read .rating file and Return dok matrix.\n",
    "        The first line of .rating file is: num_users\\t num_items\n",
    "        '''\n",
    "        # Get number of users and items\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                u, i = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, u)\n",
    "                num_items = max(num_items, i)\n",
    "                line = f.readline()\n",
    "        # Construct matrix\n",
    "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                if (rating > 0):\n",
    "                    mat[user, item] = 1.0\n",
    "                line = f.readline()\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f74a771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_instance = Dataset(r\"previous_code\\neural_collaborative_filtering\\Data\\ml-1m\")\n",
    "data_instance.num_users, data_instance.num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66431431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dictionary Of Keys sparse matrix of dtype 'float32'\n",
       "\twith 994169 stored elements and shape (6040, 3706)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_instance.trainMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97f91f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 99)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_instance.testNegatives), len(data_instance.testNegatives[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ef37049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_instance.testRatings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c858a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b40bae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from time import time\n",
    "#from numba import jit, autojit\n",
    "\n",
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_testNegatives = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _testNegatives\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _testNegatives = testNegatives\n",
    "    _K = K\n",
    "\n",
    "    hits, ndcgs = [],[]\n",
    "    if(num_thread > 1): # Multi-thread\n",
    "        pool = multiprocessing.Pool(processes=num_thread)\n",
    "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        hits = [r[0] for r in res]\n",
    "        ndcgs = [r[1] for r in res]\n",
    "        return (hits, ndcgs)\n",
    "    # Single thread\n",
    "    for idx in range(len(_testRatings)):\n",
    "        (hr,ndcg) = eval_one_rating(idx)\n",
    "        hits.append(hr)\n",
    "        ndcgs.append(ndcg)\n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    items = _testNegatives[idx]\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    predictions = _model.predict([users, np.array(items)],\n",
    "                                 batch_size=100, verbose=0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "\n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cf45637",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35920ec8",
   "metadata": {},
   "source": [
    "## GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "705a6ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/dhruv/Documents/DA-IICT/Arpit_rana/MajorProject/previous_code/neural_collaborative_filtering/Data')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "Path(os.getcwd(), \"previous_code/neural_collaborative_filtering/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6771d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations: \n",
      "path : c:\\Users\\dhruv\\Documents\\DA-IICT\\Arpit_rana\\MajorProject\\previous_code\\neural_collaborative_filtering\\Data\n",
      "dataset : ml-1m\n",
      "regs : [0, 0]\n",
      "lr : 0.001\n",
      "batch_size : 256\n",
      "epochs : 1\n",
      "learner : adam\n",
      "num_factors : 10\n",
      "num_layers : 3\n",
      "num_neg : 2\n",
      "verbose : 2\n",
      "out : True\n"
     ]
    }
   ],
   "source": [
    "configurations = {\n",
    "    'path': Path(os.getcwd(), \"previous_code/neural_collaborative_filtering/Data\"),\n",
    "    'dataset': 'ml-1m',\n",
    "    'regs': [0, 0],\n",
    "    'lr': 0.001,          ## Learning Rate\n",
    "    'batch_size': 256,    ## Batch Size\n",
    "    'epochs': 1,          ## Training Epochs\n",
    "    'learner': 'adam',\n",
    "    'num_factors': 10,\n",
    "    'num_layers': 3,\n",
    "    'num_neg': 2,\n",
    "    'verbose': 2,\n",
    "    'out': True,\n",
    "}\n",
    "\n",
    "print('Configurations: ')\n",
    "for key, value in configurations.items():\n",
    "  print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa9971fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done [18.5 s]. #user=6040, #item=3706, #train=994169, #test=6040\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "t1 = time()\n",
    "\n",
    "dataset_path = os.path.join(configurations['path'], configurations['dataset'])\n",
    "# print(dataset_path)\n",
    "\n",
    "dataset = Dataset(dataset_path)\n",
    "\n",
    "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
    "num_users, num_items = train.shape\n",
    "print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
    "      %(time()-t1, num_users, num_items, train.nnz, len(testRatings)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07214e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dictionary Of Keys sparse matrix of dtype 'float32'\n",
       "\twith 994169 stored elements and shape (6040, 3706)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35604d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994169"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8e22998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testRatings), len(testRatings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c90f7b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 99)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testNegatives), len(testNegatives[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fb278e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, concatenate, multiply\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42ac4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GMF_model(num_users, num_items, latent_dim, regs=[0,0]):\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MF_Embedding_User = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(regs[0]))(user_input)\n",
    "    MF_Embedding_Item = Embedding(input_dim=num_items, output_dim=latent_dim, name='item_embedding',\n",
    "                                    embeddings_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    embeddings_regularizer=regularizers.l2(regs[1]))(item_input)\n",
    "\n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MF_Embedding_User)\n",
    "    item_latent = Flatten()(MF_Embedding_Item)\n",
    "\n",
    "    # Element-wise product of user and item embeddings\n",
    "    predict_vector = multiply([user_latent, item_latent])\n",
    "\n",
    "    # Final prediction layer\n",
    "    #prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)\n",
    "    prediction = Dense(1, activation='sigmoid', name = 'prediction')(predict_vector)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input],\n",
    "                outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa661c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    num_users = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u, j) in train:\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83527ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,060</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m60,400\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │     \u001b[38;5;34m37,060\u001b[0m │ item_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m11\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,471</span> (380.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,471\u001b[0m (380.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,471</span> (380.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,471\u001b[0m (380.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = get_GMF_model(num_users, num_items, configurations['num_factors'], configurations['regs'])\n",
    "if configurations['learner'].lower() == \"adagrad\":\n",
    "    model.compile(optimizer=Adagrad(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=RMSprop(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "elif configurations['learner'].lower() == \"adam\":\n",
    "    model.compile(optimizer=Adam(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "else:\n",
    "    model.compile(optimizer=SGD(learning_rate=configurations['lr']), loss='binary_crossentropy')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12cc5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK = 10\n",
    "evaluation_threads = 1 #mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33116deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.0940, NDCG = 0.0442\t [530.4 s]\n"
     ]
    }
   ],
   "source": [
    "# Init performance\n",
    "t1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "#mf_embedding_norm = np.linalg.norm(model.get_layer('user_embedding').get_weights())+np.linalg.norm(model.get_layer('item_embedding').get_weights())\n",
    "#p_norm = np.linalg.norm(model.get_layer('prediction').get_weights()[0])\n",
    "print('Init: HR = %.4f, NDCG = %.4f\\t [%.1f s]' % (hr, ndcg, time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f610541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994169\n",
      "2982507\n",
      "2982507\n",
      "[(2982507,), (2982507,)]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "\n",
    "for epoch in range(configurations['epochs']):\n",
    "    t1 = time()\n",
    "    # Generate training instances\n",
    "    print(len(train))\n",
    "    user_input, item_input, labels = get_train_instances(train, configurations['num_neg'])\n",
    "    print(len(user_input))\n",
    "    print(len(item_input))\n",
    "    # break\n",
    "    \n",
    "    # Training\n",
    "    print([np.array(user_input).shape, np.array(item_input).shape])\n",
    "\n",
    "    break\n",
    "\n",
    "    hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                      np.array(labels), # labels\n",
    "                      batch_size=configurations['batch_size'], epochs=1, verbose=0, shuffle=True)\n",
    "    t2 = time()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch % configurations['verbose'] == 0:\n",
    "        \n",
    "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "        \n",
    "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "        \n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]'\n",
    "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        \n",
    "        if hr > best_hr:\n",
    "        \n",
    "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "            model_out_file = '%s_GMF_%d.weights.h5' %(configurations['dataset'], configurations['num_factors'])\n",
    "        \n",
    "            if configurations['out'] > 0:\n",
    "                model.save_weights(model_out_file, overwrite=True)\n",
    "        \n",
    "            print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "            \n",
    "# if configurations['out'] > 0:\n",
    "    \n",
    "#     print(\"The best GMF model is saved to %s\" %(model_out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d87cc8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1988338"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "994169*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d11177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf-recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
